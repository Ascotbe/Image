{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ca116e2-6d90-4736-bb79-206db0417309",
   "metadata": {},
   "source": [
    "https://paddlepedia.readthedocs.io/\n",
    "## Softmax 回归\n",
    "\n",
    "Softmax回归是逻辑回归 (Logistic Regression) 的推广，逻辑回归适用于二元分类的问题，而Softmax回归适用于多分类的问题。\n",
    "\n",
    "与线性回归一样，softmax回归也是一个单层神经网络。 由于计算每个输出$o_1$、$o_2$和$o_3$取决于 所有输入$x_1$、$x_2$、$x_3$和$x_4$， 所以softmax回归的输出层也是全连接层。\n",
    "\n",
    "![softmaxreg.svg](https://raw.githubusercontent.com/Ascotbe/Image/master/SoftmaxRegression/1.svg)\n",
    "\n",
    "\n",
    "![img](https://raw.githubusercontent.com/Ascotbe/Image/master/SoftmaxRegression/2.png)\n",
    "\n",
    "![img](https://raw.githubusercontent.com/Ascotbe/Image/master/SoftmaxRegression/3.png)\n",
    "\n",
    "\n",
    "\n",
    "Softmax回归是使用Softmax运算使得最后一层输出的机率分布总和为1，举一个例子，假设我们要辨识手写数字0~9，输入一张数字的影像后，经由Softmax 回归，最后将会输出该影像属于0 ~ 9 个别的机率为何，且其个别的机率总和为1。\n",
    "\n",
    "$$\\hat{\\mathbf{y}}=\\operatorname{softmax}(\\mathbf{o}) \\quad \\text { 其中 } \\quad \\hat{y}_{j}=\\frac{\\exp \\left(o_{j}\\right)}{\\sum_{k} \\exp \\left(o_{k}\\right)}$$\n",
    "\n",
    "Softmax 函数通常会放在类神经网路的最后一层，将最后一层所有节点的输出都通过指数函数 (exponential function)，并将结果相加作为分母，个别的输出作为分子。\n",
    "\n",
    "![img](https://raw.githubusercontent.com/Ascotbe/Image/master/SoftmaxRegression/4.jpeg)\n",
    "\n",
    "### 实际计算举例\n",
    "\n",
    "$$\\left[\\begin{array}{c}\n",
    "1.4 \\\\\n",
    "-0.1 \\\\\n",
    "0.3\n",
    "\\end{array}\\right] \\rightarrow \\operatorname{softmax} \\rightarrow\\left[\\begin{array}{c}\n",
    "\\frac{\\mathrm{e}^{1.4}}{\\mathrm{e}^{1.4}+\\mathrm{e}^{-0.1}+\\mathrm{e}^{0.3}} \\\\\n",
    "\\frac{\\mathrm{e}^{-0.1}}{\\mathrm{e}^{1.4}+\\mathrm{e}^{-0.1}+\\mathrm{e}^{0.3}} \\\\\n",
    "\\frac{\\mathrm{e}^{0.3}}{\\mathrm{e}^{1.4}+\\mathrm{e}^{-0.1}+\\mathrm{e}^{0.3}}\n",
    "\\end{array}\\right]=\\left[\\begin{array}{l}\n",
    "0.643 \\\\\n",
    "0.143 \\\\\n",
    "0.214\n",
    "\\end{array}\\right]$$\n",
    "\n",
    "\n",
    "## 手写辨识实作\n",
    "\n",
    "手写辨识是一个非常经典的深度学习入门范例，该范例是输入一张手写数字 0 ~ 9 的影像，并且通过类神经网路预测该影像为 0 ~ 9 哪一个数字。\n",
    "\n",
    "![img](https://raw.githubusercontent.com/Ascotbe/Image/master/SoftmaxRegression/5.png)\n",
    "\n",
    "\n",
    "\n",
    "在Softmax 回归这个例子中，我们使用的是TensorFlow 官方提供的MNIST 资料集，MNIST 资料集中的影像是28 x 28 = 784 的手写数字影像，如果将其中一张影像的像素(pixels) 以矩阵的方式呈现，可以看到那些数值所呈现的形状即是手写数字的形状，所以我们将利用这些数值来预测手写数字。\n",
    "\n",
    "![img](https://raw.githubusercontent.com/Ascotbe/Image/master/SoftmaxRegression/6.png)\n",
    "\n",
    "## 什么是One-hot encoding？\n",
    "\n",
    "One-Hot编码: 一种简单的单词编码方式。在NLP领域，如何将单词数值化呢，One-Hot编码就是一种很简单的方式。假设我们现在有单词数量为$N$的词表，那可以生成一个长度为$N$\n",
    "的向量来表示一个单词，在这个向量中该单词对应的位置数值为1，其余单词对应的位置数值全部为0。举例如下：\n",
    "\n",
    "词典: [queen, king, man, woman, boy, girl ]\n",
    "\n",
    "![image.png](https://raw.githubusercontent.com/Ascotbe/Image/master/SoftmaxRegression/7.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f915771e-aa1f-40bc-b859-3575159ca2a8",
   "metadata": {},
   "source": [
    "\n",
    "## 导入数据集\n",
    "\n",
    "本节我们将使用Fashion-MNIST数据集， 并设置数据迭代器的批量大小为256\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "24cff34f-d297-4421-9e9d-c5b94ca07abb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7ff1dab2b520>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from IPython import display\n",
    "from d2l import torch as d2l\n",
    "\n",
    "batch_size = 256 #每次返回256张图片\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)\n",
    "print(train_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23edb77e-9f0e-4ef0-93ad-190091cf209f",
   "metadata": {},
   "source": [
    "\n",
    "## 定义类神经网路模型\n",
    "\n",
    "Fashion-MNIST的影像是28(width)×28(height)=784(pixels)。本节将展平每个图像，把它们看作长度为784的向量。 在后面的章节中，我们将讨论能够利用图像空间结构的特征， 但现在我们暂时只把每个像素位置看作一个特征。\n",
    "\n",
    "回想一下，在softmax回归中，我们的输出与类别一样多。因为我们的数据集有10个类别，所以网络输出维度为10。因此，权重将构成一个$784*10$\n",
    "的矩阵， 偏置将构成一个$1*10$的行向量。与线性回归一样，我们将使用正态分布初始化我们的权重$W$，偏置初始化为0。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c8cd2e4-6341-483b-8750-025f3d84dacb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.5018e-02,  1.6499e-02,  1.3063e-02,  ...,  9.3903e-03,\n",
      "          2.9487e-03, -1.0379e-02],\n",
      "        [-2.3555e-04,  3.4315e-03,  2.1076e-02,  ..., -1.0851e-03,\n",
      "          3.4873e-03,  9.5387e-03],\n",
      "        [ 1.0830e-02, -1.3425e-03, -1.1698e-02,  ...,  6.3264e-03,\n",
      "          4.5914e-03,  1.2329e-02],\n",
      "        ...,\n",
      "        [ 1.5727e-02, -3.6981e-05,  1.5651e-02,  ..., -3.0547e-03,\n",
      "          2.2678e-03,  2.2194e-02],\n",
      "        [ 2.4542e-03,  5.8998e-03, -4.0210e-03,  ...,  4.3958e-03,\n",
      "         -9.6807e-03, -7.4245e-03],\n",
      "        [ 1.5023e-02,  1.2167e-03, -2.9214e-03,  ..., -1.0596e-02,\n",
      "          1.8431e-02, -1.4767e-02]], requires_grad=True)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "num_inputs = 784\n",
    "num_outputs = 10\n",
    "\n",
    "W = torch.normal(0, 0.01, size=(num_inputs, num_outputs), requires_grad=True)\n",
    "b = torch.zeros(num_outputs, requires_grad=True)\n",
    "print(W)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e5b1ce-1fde-4609-819f-aa45c5eb358e",
   "metadata": {},
   "source": [
    "## 定义softmax操作\n",
    " 给定一个矩阵X，我们可以对所有元素求和（默认情况下）。 也可以只求同一个轴上的元素，即同一列（轴0）或同一行（轴1）。 如果X是一个形状为(2, 3)的张量，我们对列进行求和， 则结果将是一个具有形状(3,)的向量。 当调用sum运算符时，我们可以指定保持在原始张量的轴数，而不折叠求和的维度。 这将产生一个具有形状(1, 3)的二维张量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bc9c774b-1d49-4332-814c-0bfc31114d51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]]) \n",
      " torch.Size([2, 3]) \n",
      "--------------------\n",
      "tensor([[5., 7., 9.]]) \n",
      " torch.Size([1, 3]) \n",
      "--------------------\n",
      "tensor([[ 6.],\n",
      "        [15.]]) \n",
      " torch.Size([2, 1]) \n",
      "--------------------\n",
      "tensor([ 6., 15.]) \n",
      " torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "X = torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "\n",
    "#torch.sum(input, list: dim, bool: keepdim=False, dtype=None) → Tensor　\n",
    "#input:输入一个tensor\n",
    "#dim:要求和的维度，可以是一个列表\n",
    "#keepdim:是否保持求和维度个维度，如果需要保持应当keepdim=True \n",
    "\n",
    "print(X,\"\\n\",X.shape,\"\\n--------------------\")\n",
    "print(X.sum(0, keepdim=True),\"\\n\",X.sum(0, keepdim=True).shape,\"\\n--------------------\")\n",
    "print(X.sum(1, keepdim=True),\"\\n\",X.sum(1, keepdim=True).shape,\"\\n--------------------\")\n",
    "print(X.sum(1),\"\\n\",X.sum(1).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66392219-19b3-44de-a905-48587eff0742",
   "metadata": {
    "tags": []
   },
   "source": [
    "回想一下，**实现softmax**由三个步骤组成：\n",
    "\n",
    "1. 对每个项求幂（使用`exp`）；\n",
    "1. 对每一行求和（小批量中每个样本是一行），得到每个样本的规范化常数；\n",
    "1. 将每一行除以其规范化常数，确保结果的和为1。\n",
    "\n",
    "在查看代码之前，我们回顾一下这个表达式：\n",
    "\n",
    "$$\n",
    "\\mathrm{softmax}(\\mathbf{X})_{ij} = \\frac{\\exp(\\mathbf{X}_{ij})}{\\sum_k \\exp(\\mathbf{X}_{ik})}.\n",
    "$$\n",
    "\n",
    "分母或规范化常数，有时也称为*配分函数*（其对数称为对数-配分函数）。\n",
    "该名称来自[统计物理学](https://en.wikipedia.org/wiki/Partition_function_(statistical_mechanics))中一个模拟粒子群分布的方程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e337288-4185-432d-92a7-c0e27d9483b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def softmax(X):\n",
    "    X_exp = torch.exp(X)\n",
    "    #print(X_exp)\n",
    "    partition = X_exp.sum(1, keepdim=True) #如果有keepdim那么就是列的维度\n",
    "    #print(partition)\n",
    "    return X_exp / partition  # 这里应用了广播机制"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539e6efe-6522-4854-a8ac-a4c173f3b0de",
   "metadata": {},
   "source": [
    "正如上述代码，对于任何随机输入，我们将每个元素变成一个非负数。 此外，依据概率原理，每行总和为1。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bceb31-113e-4694-b2b7-07d747a93c24",
   "metadata": {},
   "source": [
    "官方文档：https://pytorch.org/docs/1.2.0/torch.html#torch.exp\n",
    "\n",
    " torch.exp的用法样例可以参考下面内容，常数$e$等于2.704"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f2c8a49b-fdad-40a8-ac4a-66a8d029049f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ccccc等于:tensor([[  2.7183,   7.3891,  20.0855],\n",
      "        [ 54.5982, 148.4132, 403.4288]])\n",
      "X等于:tensor([[ 0.1136,  0.1070,  0.7513, -1.6653,  1.0956],\n",
      "        [-1.2548, -0.6776, -0.5557, -0.1125, -0.5532]])\n",
      "X_exp等于:tensor([[1.1203, 1.1129, 2.1197, 0.1891, 2.9909],\n",
      "        [0.2851, 0.5078, 0.5737, 0.8936, 0.5751]])\n",
      "partition等于:tensor([[7.5329],\n",
      "        [2.8353]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[0.1487, 0.1477, 0.2814, 0.0251, 0.3970],\n",
       "         [0.1006, 0.1791, 0.2023, 0.3152, 0.2028]]),\n",
       " tensor([1., 1.]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def softmax_test(X):\n",
    "    print(f\"X等于:{X}\")\n",
    "    X_exp = torch.exp(X)\n",
    "    print(f\"X_exp等于:{X_exp}\")\n",
    "    partition = X_exp.sum(1, keepdim=True) #如果有keepdim那么就是列的维度\n",
    "    print(f\"partition等于:{partition}\")\n",
    "    return X_exp / partition  # 这里应用了广播机制\n",
    "ccccc=torch.exp(torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]]))\n",
    "print(f\"ccccc等于:{ccccc}\")\n",
    "X = torch.normal(0, 1, (2, 5))\n",
    "X_prob = softmax_test(X)\n",
    "X_prob, X_prob.sum(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb369d32-f635-42d2-b5f6-43d1e9906f8d",
   "metadata": {},
   "source": [
    "注意，虽然这在数学上看起来是正确的，但我们在代码实现中有点草率。 矩阵中的非常大或非常小的元素可能造成数值上溢或下溢，但我们没有采取措施来防止这点。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5542d7c-4a3c-4550-b638-edb20a0025ee",
   "metadata": {},
   "source": [
    "## 定义模型\n",
    "定义softmax操作后，我们可以实现softmax回归模型。 下面的代码定义了输入如何通过网络映射到输出。 注意，将数据传递到模型之前，我们使用reshape函数将每张原始图像展平为向量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bda13f7-3120-42ca-9339-dc36bc9ae349",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def net(X):\n",
    "    return softmax(torch.matmul(X.reshape((-1, W.shape[0])), W) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3466c48-8b43-4111-9e0b-873df75a3e81",
   "metadata": {},
   "source": [
    "## 定义损失函数\n",
    "接下来，我们实现交叉熵损失函数。 这可能是深度学习中最常见的损失函数，因为目前分类问题的数量远远超过回归问题的数量。\n",
    "\n",
    "交叉熵损失函数：https://blog.csdn.net/b1055077005/article/details/100152102\n",
    "\n",
    "底是10的对数叫：常用对数 $\\log_{10}(x)$，有时写为$\\log(x)$\n",
    "\n",
    "### 交叉熵损失函数原理详解\n",
    "\n",
    "之前在代码中经常看见交叉熵**损失函数**(CrossEntropy Loss)，只知道它是分类问题中经常使用的一种损失函数，对于其内部的原理总是模模糊糊，而且一般使用交叉熵作为损失函数时，在模型的输出层总会接一个softmax函数，至于为什么要怎么做也是不懂，所以专门花了一些时间打算从原理入手，搞懂它，故在此写一篇博客进行总结，以便以后翻阅。\n",
    "\n",
    "\n",
    "\n",
    "#### 交叉熵简介\n",
    "\n",
    "交叉熵是信息论中的一个重要概念，主要用于度量两个概率分布间的差异性，要理解交叉熵，需要先了解下面几个概念。\n",
    "\n",
    "\n",
    "\n",
    "#### 信息量\n",
    "信息奠基人香农（Shannon）认为“信息是用来**消除**随机**不确定性**的东西”，也就是说衡量信息量的大小就是看这个信息消除不确定性的程度。\n",
    "\n",
    "- “太阳从东边升起”，这条信息并没有减少不确定性，因为太阳肯定是从东边升起的，这是一句废话，信息量为0。\n",
    "\n",
    "- “2018年中国队成功进入世界杯”，从直觉上来看，这句话具有很大的信息量。因为中国队进入世界杯的不确定性因素很大，而这句话消除了进入世界杯的不确定性，所以按照定义，这句话的信息量很大。\n",
    "\n",
    "根据上述可总结如下：**信息量的大小与信息发生的概率成反比**。概率越大，信息量越小。概率越小，信息量越大。\n",
    "\n",
    "设某一事件发生的概率为$P(x)$，其信息量表示为：\n",
    "\n",
    "$$\\mathrm{I}(\\mathrm{x})=-\\log (\\mathrm{P}(\\mathrm{x}))$$\n",
    "\n",
    "\n",
    "其中$I(x)$表示信息量，这里$\\log$表示以$e$为底的自然对数。\n",
    "\n",
    "#### 信息熵\n",
    "\n",
    "信息摘也被称为熵，用来表示所有信息量的期望。\n",
    "期望是试验中每次可能结果的概率乘以其结果的总和。\n",
    "所以信息量的摘可表示为：（这里的$\\mathrm{X}$是一个离散型随机变量）\n",
    "\n",
    "$$\\mathrm{H}(\\mathbf{X}) = -\\sum_{\\mathrm{i} = 1}^{\\mathrm{n}} \\mathrm{P}(\\mathrm{x}_{\\mathrm{i}}) \\log (\\mathrm{P}(\\mathrm{x}_{\\mathrm{i}}))\\quad\\left(\\mathbf{X} = \\mathrm{x}_{1}, \\mathrm{x}_{2}, \\mathrm{x}_{3} \\ldots, \\mathrm{x}_{\\mathrm{n}}\\right)$$\n",
    "\n",
    "\n",
    "使用明天的天气概率来计算其信息熵:\n",
    "\n",
    "| 序号 | 事件       | 概率P | 信息量       |\n",
    "| ---- | ---------- | ----- | ------------ |\n",
    "| 1    | 明天是晴天 | 0.5   | -log(0.5) |\n",
    "| 2    | 明天出雨天 | 0.2   | -log(0.2) |\n",
    "| 3    | 多云       | 0.3   | -log(0.3)|\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "公式的话\n",
    "\n",
    "\n",
    "$$\\mathrm{H}(\\mathbf{X})=-(0.5 * \\log (0.5)+0.2 * \\log (0.2)+0.3 * \\log (0.3))$$\n",
    "\n",
    "对于0-1分布的问题，由于其结果只用两种情况，是或不是，设某一件事情发生的概率为$P(x)$，则另一件事情发生的概率为$1 − P ( x )$，所以对于0-1分布的问题，计算熵的公式可以简化如下：\n",
    "\n",
    "$$\\begin{array}{c}\n",
    "\\mathrm{H}(\\mathbf{X})=-\\sum_{\\mathrm{n}=1}^{\\mathrm{n}} \\mathrm{P}\\left(\\mathrm{x}_{\\mathrm{i}} \\log \\left(\\mathrm{P}\\left(\\mathrm{x}_{\\mathrm{i}}\\right)\\right)\\right) \\\\\n",
    "=-[\\mathrm{P}(\\mathrm{x}) \\log (\\mathrm{P}(\\mathrm{x}))+(1-\\mathrm{P}(\\mathrm{x})) \\log (1-\\mathrm{P}(\\mathrm{x}))] \\\\\n",
    "=-\\mathrm{P}(\\mathrm{x}) \\log (\\mathrm{P}(\\mathrm{x}))-(1-\\mathrm{P}(\\mathrm{x})) \\log (1-\\mathrm{P}(\\mathrm{x}))\n",
    "\\end{array}$$\n",
    "\n",
    "\n",
    "#### 相对熵 (KL散度)\n",
    "如果对于同一个随机变量$X$有两个单独的概率分布$\\mathrm{P}(\\mathrm{x})$和$\\mathrm{Q}(\\mathrm{x})$，则我们可以使用KL散度来衡量这**两个概率分布之间的差异**。\n",
    "\n",
    "下面直接列出公式，再举例子加以说明。\n",
    "\n",
    "$$D_{K L}(p \\| q)=\\sum_{i=1}^{n} p\\left(x_{i}\\right) \\log \\left(\\frac{p\\left(x_{i}\\right)}{q\\left(x_{i}\\right)}\\right)$$\n",
    "\n",
    "\n",
    "在机器学习中，常常使用$\\mathrm{P}(\\mathrm{x})$来表示样本的真实分布，$\\mathrm{Q}(\\mathrm{x})$来表示模型所预测的分布，比如在一个三分类任务中 (例如，猫狗马分类器)，$\\mathrm{x}_{1}, \\mathrm{x}_{2}, \\mathrm{x}_{3}$分别代表猫，狗，马，例如一张猫的图片真实分布$\\mathrm{P}(\\mathrm{X})=[1,0,0]$，预测分布$\\mathrm{Q}(\\mathrm{X})=[0.7,0.2,0.1]$，计算KL散度:\n",
    "\n",
    "$$\\begin{array}{c}\n",
    "D_{K L}(p \\| q)=\\sum_{i=1}^{n} p\\left(x_{i}\\right) \\log \\left(\\frac{p\\left(x_{i}\\right)}{q\\left(x_{i}\\right)}\\right) \\\\\n",
    "=p\\left(x_{1}\\right) \\log \\left(\\frac{p\\left(x_{1}\\right)}{q\\left(x_{1}\\right)}\\right)+p\\left(x_{2}\\right) \\log \\left(\\frac{p\\left(x_{2}\\right)}{q\\left(x_{2}\\right)}\\right)+p\\left(x_{3}\\right) \\log \\left(\\frac{p\\left(x_{3}\\right)}{q\\left(x_{3}\\right)}\\right) \\\\\n",
    "=1 * \\log \\left(\\frac{1}{0.7}\\right)=0.36\n",
    "\\end{array}$$\n",
    "\n",
    "KL散度越小，表示$\\mathrm{P}(\\mathrm{x})$与$\\mathrm{Q}(\\mathrm{x})$的分布更加接近，可以通过反复训练$\\mathrm{Q}(\\mathrm{x})$来使$\\mathrm{Q}(\\mathrm{x})$的分布逼近$\\mathrm{P}(\\mathrm{x})$。\n",
    "\n",
    "\n",
    "#### 交叉嫡\n",
    "\n",
    "首先将KL散度公式拆开：\n",
    "\n",
    "$$\\begin{array}{c}\n",
    "D_{K L}(p \\| q)=\\sum_{i=1}^{n} p\\left(x_{i}\\right) \\log \\left(\\frac{p\\left(x_{i}\\right)}{q\\left(x_{i}\\right)}\\right) \\\\\n",
    "=\\sum_{i=1}^{n} p\\left(x_{i}\\right) \\log \\left(p\\left(x_{i}\\right)\\right)-\\sum_{i=1}^{n} p\\left(x_{i}\\right) \\log \\left(q\\left(x_{i}\\right)\\right) \\\\\n",
    "=-H(p(x))+\\left[-\\sum_{i=1}^{n} p\\left(x_{i}\\right) \\log \\left(q\\left(x_{i}\\right)\\right)\\right]\n",
    "\\end{array}$$\n",
    "\n",
    "\n",
    "前者$\\mathrm{H}(\\mathrm{p}(\\mathrm{x}))$表示信息熵，后者即为交叉熵，**KL散度  = 交叉熵 - 信息摘**\n",
    "\n",
    "交叉摘公式表示为:\n",
    "\n",
    "$$H(p, q)=-\\sum_{i=1}^{n} p\\left(x_{i}\\right) \\log \\left(q\\left(x_{i}\\right)\\right)$$\n",
    "\n",
    "\n",
    "在机器学习训练网络时，输入数据与标签常常已经确定，那么真实概率分布$\\mathrm{P}(\\mathrm{x})$也就确定下来了，所以信息熵在这里就是一个常量。由于KL散度的值表示真实概率分布$\\mathrm{P}(\\mathrm{x})$与预测概率分布$\\mathrm{Q}(\\mathrm{x})$之间的差异，值越小表示预测的结果越好，所以需要最小化KL散度，而交叉嫡等于KL散度加上一个常量（信息摘），且公式相比KL散度更加容易计算，所以在机器学习中常常使用交叉嫡损失函数来计算loss就行了。\n",
    "\n",
    "#### 交叉嫡在单分类问题中的应用\n",
    "\n",
    "在线性回归问题中，常常使用MSE(Mean Squared Error)作为loss函数，而在分类问题中常常使用交叉熵作为loss函数。\n",
    "\n",
    "下面通过一个例子来说明如何计算交叉摘损失值。\n",
    "\n",
    "假设我们输入一张狗的图片，标签与预测值如下:\n",
    "\n",
    "\n",
    "| *     | 猫   | 狗   | 马   |\n",
    "| ----- | ---- | ---- | ---- |\n",
    "| Label | 0    | 1    | 0    |\n",
    "| Pred  | 0.2  | 0.7  | 0.1  |\n",
    "\n",
    "\n",
    "那么loss\n",
    "\n",
    "$$\\text { loss }=-(0 * \\log (0.2)+1 * \\log (0.7)+0 * \\log (0.1))=0.36$$\n",
    "\n",
    "\n",
    "一个batch的loss为\n",
    "\n",
    "$$\\operatorname{loss}=-\\frac{1}{m} \\sum_{i=1}^{m} \\sum_{j=1}^{n} p\\left(x_{i j}\\right) \\log \\left(q\\left(x_{i j}\\right)\\right)$$\n",
    "\n",
    "\n",
    "其中$m$表示样本个数。\n",
    "\n",
    "#### 总结：\n",
    "\n",
    "- 交叉熵能够衡量同一个随机变量中的两个不同概率分布的差异程度，在机器学习中就表示为真实概率分布与预测概率分布之间的差异。交叉熵的值越小，模型预测效果就越好。\n",
    "\n",
    "- 交叉熵在分类问题中常常与softmax是标配，softmax将输出的结果进行处理，使其多个分类的预测值和为1，再通过交叉熵来计算损失。\n",
    "\n",
    "### 用torch实现\n",
    "回顾一下，交叉熵采用真实标签的预测概率的负对数似然。 这里我们不使用Python的for循环迭代预测（这往往是低效的）， 而是通过一个运算符选择所有元素。 下面，我们创建一个数据样本y_hat，其中包含2个样本在3个类别的预测概率， 以及它们对应的标签y。 有了y，我们知道在第一个样本中，第一类是正确的预测； 而在第二个样本中，第三类是正确的预测。 然后使用y作为y_hat中概率的索引， 我们选择第一个样本中第一个类的概率和第二个样本中第三个类的概率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "736eb229-6b87-4954-ba4d-2af5b8738bd5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 2])\n",
      "tensor([[0.1000, 0.3000, 0.6000],\n",
      "        [0.3000, 0.2000, 0.5000]])\n",
      "对于第0样本y_hat，拿出y[0]（值为0）对应的那个元素，对于第1个样本y_hat，拿出y[1]（值为2）对应那个元素----------tensor([0.1000, 0.5000])\n",
      "等同于:y_hat[[0, 1], [0,2]]----------tensor([0.1000, 0.5000])\n",
      "y_hat[[0, 1], [2,1]]---------tensor([0.6000, 0.2000])\n"
     ]
    }
   ],
   "source": [
    "y = torch.tensor([0, 2])\n",
    "print(y)\n",
    "y_hat = torch.tensor([[0.1, 0.3, 0.6], [0.3, 0.2, 0.5]])\n",
    "print(y_hat)\n",
    "#y_hat是一个2*3的数组。y_hat[[0,1],y]中的[0,1]指的是第一行和第二行的索引，后面的y等价于[0,2]。那么可以这么理解y_hat[0,0]和y_hat[1,2]。\n",
    "print(f\"对于第0样本y_hat，拿出y[0]（值为0）对应的那个元素，对于第1个样本y_hat，拿出y[1]（值为2）对应那个元素----------{y_hat[[0, 1], y]}\")\n",
    "print(f\"等同于:y_hat[[0, 1], [0,2]]----------{y_hat[[0, 1], [0,2]]}\")\n",
    "print(f\"y_hat[[0, 1], [2,1]]---------{y_hat[[0, 1], [2,1]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2976de9-28a1-414f-843c-6fda99cc281d",
   "metadata": {},
   "source": [
    "现在我们只需一行代码就可以实现交叉熵损失函数。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b0df8434-89ae-4763-8135-0fa3c2177d55",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(y_hat):2\n",
      "range(len(y_hat)):range(0, 2)\n",
      "tmp_:tensor([0.1000, 0.5000])\n",
      "-torch.log(torch.tensor(0.1)):2.3025851249694824\n",
      "-torch.log(torch.tensor(0.5)):0.6931471824645996\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([2.3026, 0.6931])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cross_entropy(y_hat, y):\n",
    "    return - torch.log(y_hat[range(len(y_hat)), y])\n",
    "\n",
    "def tmp_cross_entropy(y_hat, y):\n",
    "    print(f\"len(y_hat):{len(y_hat)}\")\n",
    "    print(f\"range(len(y_hat)):{range(len(y_hat))}\")\n",
    "    tmp_=y_hat[range(len(y_hat)), y]\n",
    "    print(f\"tmp_:{tmp_}\")\n",
    "    print(f\"-torch.log(torch.tensor(0.1)):{-torch.log(torch.tensor(0.1))}\")\n",
    "    print(f\"-torch.log(torch.tensor(0.5)):{-torch.log(torch.tensor(0.5))}\")\n",
    "    return - torch.log(tmp_)\n",
    "\n",
    "tmp_cross_entropy(y_hat, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b2833e-f4d8-4224-b788-8ca514fde6e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 深度学习中的轴/axis/dim全解\n",
    "\n",
    "在深度学习中，轴，指的就是张量的层级，一般通过参数axis/dim来设定。很多张量的运算、神经网络的构建，都会涉及到轴，但到底取哪个轴，却不是那么容易把握。\n",
    "\n",
    "下面会针对轴/axis/dim，基于 Pytorch 的代码和实例，尝试去理清张量运算中轴/axis/dim的设定。\n",
    "\n",
    "### 轴的概念\n",
    "\n",
    "对于一个张量，它的shape有几维，就对应有几个轴，也就对应着张量的层级，最直观的可以通过看最前面的方括号数量来判断。\n",
    "\n",
    "```python\n",
    "import torch\n",
    "a = torch.Tensor([[1,2,3], [4,5,6]])\n",
    "b = torch.Tensor([[7,8,9], [10,11,12]])\n",
    "c = torch.Tensor([[[1,2,3], [4,5,6]], [[7,8,9], [10,11,12]]])\n",
    "print(a.shape)\n",
    "\n",
    "# torch.Size([2, 3])\n",
    "```\n",
    "\n",
    "上面的张量 a 和 b，都对应两个轴。axis/dim=0 对应 shape [2, 3] 中的2，axis/dim=1 对应 shape [2, 3] 中的3，而张量 c 有三个轴。\n",
    "\n",
    "张量运算时对轴参数的设定非常常见，在 Numpy 中一般是参数axis，在 Pytorch 中一般是参数dim，但它们含义是一样的。\n",
    "\n",
    "### 轴的使用\n",
    "\n",
    "在做张量的拼接操作时，**axis/dim设定了哪个轴，那对应的轴在拼接之后张量数会发生变化**\n",
    "\n",
    "```python\n",
    ">> torch.cat((a,b), dim=0)\n",
    "tensor([[ 1.,  2.,  3.],\n",
    "        [ 4.,  5.,  6.],\n",
    "        [ 7.,  8.,  9.],\n",
    "        [10., 11., 12.]])\n",
    "\n",
    ">> torch.cat((a,b), dim=1)\n",
    "tensor([[ 1.,  2.,  3.,  7.,  8.,  9.],\n",
    "        [ 4.,  5.,  6., 10., 11., 12.]])\n",
    "```\n",
    "\n",
    "> 对于上面torch中的cat操作，当设定dim=0时，两个维度是(2,3)的张量合并成了一个(4,3)的张量，在第0维，张量数从2变成了4，第1维没有变化；当设定dim=1时，在第1维，张量数从3变成了6，第0维没有变化。\n",
    "\n",
    "在做张量的运算操作时，**axis/dim设定了哪个轴，就会遍历这个轴去做运算，其他轴顺序不变**\n",
    "\n",
    "```python\n",
    ">> torch.softmax(a, dim=0)\n",
    "tensor([[0.0474, 0.0474, 0.0474],\n",
    "        [0.9526, 0.9526, 0.9526]])\n",
    "\n",
    ">> torch.softmax(a, dim=1)\n",
    "tensor([[0.0900, 0.2447, 0.6652],\n",
    "        [0.0900, 0.2447, 0.6652]])\n",
    "```\n",
    "\n",
    "对于上面torch中的 softmax 操作，当设定 dim=0 时，就是其他轴不变，单次遍历 dim=0 轴的所有元素去做运算，上例中就相当于分别取了张量a中的第0列、第1列、第2列去做计算。\n",
    "\n",
    "换一个角度，假设用for循环去遍历一个张量，那运算中设定的dim就是被放在最内层的for循环，其它的轴保持正常的顺序。\n",
    "\n",
    "可以用下面的例子作为验证，这里tensor c 的shape 是 (m,n,p)，用for循环去计算 torch.softmax(c, dim=1)\n",
    "\n",
    "```python\n",
    "# for循环计算方式\n",
    "c = torch.Tensor([[[1,2,3], [4,5,6]], [[7,8,9], [10,11,12]]])   # shape (2,2,3)\n",
    "m,n,p = c.shape\n",
    "res = torch.zeros((m,n,p))\n",
    "for i in range(m):\n",
    "    for j in range(p):\n",
    "        res[i,:,j] = torch.softmax(torch.tensor([c[i,k,j] for k in range(n)]), dim=0)  #这里对应最内层的for循环\n",
    "\n",
    "# 库函数设定轴计算方式\n",
    "res1 = torch.softmax(c, dim=1)\n",
    "print(res.equal(res1))      # True\n",
    "```\n",
    "\n",
    "axis/dim使用小总结：\n",
    "\n",
    "1. 在做张量的拼接操作时，**axis/dim设定了哪个轴，那对应的轴在拼接之后张量数会发生变化**\n",
    "2. 在做张量的运算操作时，**axis/dim设定了哪个轴，就会遍历这个轴去做运算，其他轴顺序不变**\n",
    "\n",
    "实际上，第一条拼接操作也可以用第二条去理解，但拼接的轴张量数会发生变化更好理解和记忆。\n",
    "\n",
    "### 轴的实例\n",
    "\n",
    "其实一个轴设定的变化，会带来很大的差异，最典型的就是 BatchNorm 和 LayerNorm 了。\n",
    "\n",
    "![img](https://raw.githubusercontent.com/Ascotbe/Image/master/SoftmaxRegression/8.webp)\n",
    "\n",
    "BatchNorm 和 LayerNorm 是针对数据的不同轴去做norm，假设输入数据的维度是(N,H,W,C)，分别对应batch数，高，宽，通道数，BatchNorm 就对应dim=0，LayerNorm 就对应dim=-1，在不考虑移动平均等具体细节问题时，两者在形式上可以统一，只有一个dim参数的差别。\n",
    "\n",
    "Pytorch 的实现（简化版）如下：\n",
    "\n",
    "```python\n",
    "class Norm(nn.Module):\n",
    "    def __init__(self, num_features, variance_epsilon=1e-12):\n",
    "        super(Norm, self).__init__()\n",
    "        self.gamma = nn.Parameter(torch.ones(num_features))\n",
    "        self.beta = nn.Parameter(torch.zeros(num_features))\n",
    "        self.variance_epsilon = variance_epsilon    # 一个很小的常数，防止除0\n",
    "\n",
    "    def forward(self, x, dim):\n",
    "        u = x.mean(dim, keepdim=True)\n",
    "        s = (x - u).pow(2).mean(dim, keepdim=True)\n",
    "        x_norm = (x - u) / torch.sqrt(s + self.variance_epsilon)\n",
    "        return self.gamma * x_norm + self.beta\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4b4f42-d4f2-4351-b534-89334aabc8db",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 分类精度\n",
    "给定预测概率分布y_hat，当我们必须输出硬预测（hard prediction）时， 我们通常选择预测概率最高的类。 许多应用都要求我们做出选择。如Gmail必须将电子邮件分类为“Primary（主要邮件）”、 “Social（社交邮件）”“Updates（更新邮件）”或“Forums（论坛邮件）”。 Gmail做分类时可能在内部估计概率，但最终它必须在类中选择一个。\n",
    "### torch.argmax(input, dim=None, keepdim=False)\n",
    "\n",
    "参数说明：\n",
    "\n",
    "- input：输入的张量。\n",
    "- dim：指定在哪个维度上寻找最大值，默认为None，表示在整个张量中寻找最大值。\n",
    "- keepdim：是否保持输出张量的维度和输入张量一致，默认为False。\n",
    "\n",
    "```python\n",
    "Example:\n",
    "\n",
    ">>> a = torch.randn(4, 5)\n",
    ">>> a\n",
    "tensor([[ 2.3496, -0.2063, -0.0367,  0.4893, -0.2313],\n",
    "        [-0.7610, -0.4043, -0.3003,  0.1868, -0.6217],\n",
    "        [ 0.0706,  0.9843,  0.2633,  3.3647, -0.4209],\n",
    "        [ 0.0707,  0.6915,  0.1486, -0.0720, -0.7747]])\n",
    ">>> torch.argmax(a, dim=1)\n",
    "tensor([0, 3, 3, 1])\n",
    "\n",
    "```\n",
    "\n",
    "y_hat.argmax(dim=1)\n",
    "\n",
    "这行代码是将张量y_hat沿着第一个轴（dim=1）进行argmax操作，并将结果赋值给变量y_hat。\n",
    "\n",
    "具体来说，如果y_hat是一个二维张量（矩阵），那么argmax(dim=1)操作将会在每一行上找到最大值，并返回最大值所在的列索引。结果将会是一个一维张量，其中每个元素表示对应行的最大值所在的列索引。\n",
    "\n",
    "这行代码的目的可能是为了将模型的预测结果转换为类别标签。通过argmax操作，可以得到每个样本的预测类别。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3685492c-c805-433f-9dc1-08407997073a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def accuracy(y_hat, y):  #@save\n",
    "    \"\"\"计算预测正确的数量\"\"\"\n",
    "    #用来防止出现1维向量和第二维度维1的数据，确保两个维度都大于1，不然就等于直接输出整个张量了，等于脱裤子放屁\n",
    "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
    "        y_hat = y_hat.argmax(dim=1)\n",
    "    cmp = y_hat.type(y.dtype) == y\n",
    "    return float(cmp.type(y.dtype).sum())\n",
    "\n",
    "\n",
    "#将预测类别和真实y元素进行比较，因为做的是分类问题。\n",
    "'''\n",
    "y：tensor([0, 2])\n",
    "y_hat：tensor([[0.1000, 0.3000, 0.6000],\n",
    "        [0.3000, 0.2000, 0.5000]])\n",
    "'''\n",
    "def accuracy_test(y_hat,y):                           #给定预测值y_hat和真实值y,计算分类正确的类别数.\n",
    "    \"\"\"计算预测正确的数量\"\"\"\n",
    "    if len(y_hat.shape)>1 and y_hat.shape[1]>1:#如果y_hat是一个二维矩阵的话，它的shape>1,它的列数也>1.\n",
    "        print(\"什么都没做的时候：\")\n",
    "        print(f\"y_hat:{y_hat}\")\n",
    "        print(f\"y:{y}\")\n",
    "        print(f\"y_hat.shape:{y_hat.shape}\")\n",
    "        print(f\"y.shape:{y.shape}\")\n",
    "        print(f\"y_hat.type:{y_hat.type}\")\n",
    "        print(f\"y_hat.dtype：{y_hat.dtype}\")\n",
    "        print(f\"y.type:{y.type}\")\n",
    "        print(f\"y.dtype:{y.dtype}\")\n",
    "        y_hat=y_hat.argmax(axis=1) #对每一行求argmax-每一行中元素最大的那个下标存到y_hat里面。\n",
    "        print(\"对每一行求argmax-每一行中元素最大的那个下标存到y_hat里面:\")\n",
    "        print(f\"y_hat:{y_hat}\")\n",
    "        print(f\"y:{y}\")\n",
    "        print(f\"y_hat.shape:{y_hat.shape}\")\n",
    "        print(f\"y.shape:{y.shape}\")\n",
    "        print(f\"y_hat.type:{y_hat.type}\")\n",
    "        print(f\"y_hat.dtype：{y_hat.dtype}\")\n",
    "        print(f\"y.type:{y.type}\")\n",
    "        print(f\"y.dtype:{y.dtype}\")\n",
    "    cmp=y_hat.type(y.dtype)==y  #y_hat和y的数据类型可能不一样，把y_hat转成y的数据类型，然后对比相同下标的数据是否相同，变成一个bool的tensor。\n",
    "    print(\"y_hat和y的数据类型可能不一样，把y_hat转成y的数据类型，变成一个bool的tensor。\")\n",
    "    print(f\"y_hat.type:{y_hat.type}\")\n",
    "    print(f\"y_hat.dtype：{y_hat.dtype}\")\n",
    "    print(f\"y.type:{y.type}\")\n",
    "    print(f\"y.dtype:{y.dtype}\")\n",
    "    print(f\"cmp:{cmp}\")\n",
    "    print(\"cmp转换成y的数据类型，然后求和\")\n",
    "    cmp.type(y.dtype)\n",
    "    print(f\"y.type:{y.type}\")\n",
    "    print(f\"y.dtype:{y.dtype}\")\n",
    "    print(f\"cmp.type:{cmp.type}\")\n",
    "    print(f\"cmp.dtype:{cmp.dtype}\")\n",
    "    _t=cmp.sum()\n",
    "    print(\"True被解释为1，False被解释为0，所以后面相加为1\")\n",
    "    print(f\"cmp:{_t}\")\n",
    "    print(\"转换位浮点型\")\n",
    "    print(f\"float(cmp.type(y.dtype).sum()):{float(cmp.type(y.dtype).sum())}\")\n",
    "    return float(cmp.type(y.dtype).sum())         #转成跟y一样的形状，求和。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9049398f-fbc5-4c3a-9afb-9c9cac1436a6",
   "metadata": {},
   "source": [
    "我们将继续使用之前定义的变量y_hat和y分别作为预测的概率分布和标签。 可以看到，第一个样本的预测类别是2（该行的最大元素为0.6，索引为2），这与实际标签0不一致。 第二个样本的预测类别是2（该行的最大元素为0.5，索引为2），这与实际标签2一致。 因此，这两个样本的分类精度率为0.5。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84b66897-59c4-4768-9762-48da80f88994",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "什么都没做的时候：\n",
      "y_hat:tensor([[0.1000, 0.3000, 0.6000],\n",
      "        [0.3000, 0.2000, 0.5000]])\n",
      "y:tensor([0, 2])\n",
      "y_hat.shape:torch.Size([2, 3])\n",
      "y.shape:torch.Size([2])\n",
      "y_hat.type:<built-in method type of Tensor object at 0x7ff1dab0d260>\n",
      "y_hat.dtype：torch.float32\n",
      "y.type:<built-in method type of Tensor object at 0x7ff1dab3f830>\n",
      "y.dtype:torch.int64\n",
      "对每一行求argmax-每一行中元素最大的那个下标存到y_hat里面:\n",
      "y_hat:tensor([2, 2])\n",
      "y:tensor([0, 2])\n",
      "y_hat.shape:torch.Size([2])\n",
      "y.shape:torch.Size([2])\n",
      "y_hat.type:<built-in method type of Tensor object at 0x7ff1d98c4450>\n",
      "y_hat.dtype：torch.int64\n",
      "y.type:<built-in method type of Tensor object at 0x7ff1dab3f830>\n",
      "y.dtype:torch.int64\n",
      "y_hat和y的数据类型可能不一样，把y_hat转成y的数据类型，变成一个bool的tensor。\n",
      "y_hat.type:<built-in method type of Tensor object at 0x7ff1d98c4450>\n",
      "y_hat.dtype：torch.int64\n",
      "y.type:<built-in method type of Tensor object at 0x7ff1dab3f830>\n",
      "y.dtype:torch.int64\n",
      "cmp:tensor([False,  True])\n",
      "cmp转换成y的数据类型，然后求和\n",
      "y.type:<built-in method type of Tensor object at 0x7ff1dab3f830>\n",
      "y.dtype:torch.int64\n",
      "cmp.type:<built-in method type of Tensor object at 0x7ff1d98bd760>\n",
      "cmp.dtype:torch.bool\n",
      "True被解释为1，False被解释为0，所以后面相加为1\n",
      "cmp:1\n",
      "转换位浮点型\n",
      "float(cmp.type(y.dtype).sum()):1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy(y_hat, y) / len(y)\n",
    "\n",
    "accuracy_test(y_hat, y) / len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f76435-bb7c-48da-9ff4-b0559a0bdb2a",
   "metadata": {},
   "source": [
    "同样，对于任意数据迭代器data_iter可访问的数据集， 我们可以评估在任意模型net的精度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01f0d0bc-d507-4346-b34b-d1ff587195f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_accuracy(net, data_iter):  #@save\n",
    "    \"\"\"计算在指定数据集上模型的精度\"\"\"\n",
    "    if isinstance(net, torch.nn.Module):\n",
    "        net.eval()  # 将模型设置为评估模式\n",
    "    metric = Accumulator(2)  # 正确预测数、预测总数\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            metric.add(accuracy(net(X), y), y.numel())\n",
    "    return metric[0] / metric[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f0348b-5bd8-4b18-8e0d-7985a8970e24",
   "metadata": {},
   "source": [
    "这里定义一个实用程序类Accumulator，用于对多个变量进行累加。 在上面的evaluate_accuracy函数中， 我们在Accumulator实例中创建了2个变量， 分别用于存储正确预测的数量和预测的总数量。 当我们遍历数据集时，两者都将随着时间的推移而累加。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14968f8f-9928-48b5-9abb-a1cc2f634776",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Accumulator:  #@save\n",
    "    \"\"\"在n个变量上累加\"\"\"\n",
    "    def __init__(self, n):\n",
    "        self.data = [0.0] * n\n",
    "\n",
    "    def add(self, *args):\n",
    "        self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
    "\n",
    "    def reset(self):\n",
    "        self.data = [0.0] * len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72131a0f-138d-4b5c-8519-d2676818d4fe",
   "metadata": {},
   "source": [
    "由于我们使用随机权重初始化net模型， 因此该模型的精度应接近于随机猜测。 例如在有10个类别情况下的精度为0.1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6bd915f-ad64-4b9c-b4cc-ad20e41e706a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0702"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(net, test_iter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250c5349-d6b4-47fb-b985-eb25337c1cc4",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8c6ba21-bf46-4843-a48b-2b12e081c9e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_epoch_ch3(net, train_iter, loss, updater):  #@save\n",
    "    \"\"\"训练模型一个迭代周期（定义见第3章）\"\"\"\n",
    "    # 将模型设置为训练模式\n",
    "    if isinstance(net, torch.nn.Module):\n",
    "        net.train()\n",
    "    # 训练损失总和、训练准确度总和、样本数\n",
    "    metric = Accumulator(3)\n",
    "    for X, y in train_iter:\n",
    "        # 计算梯度并更新参数\n",
    "        y_hat = net(X)\n",
    "        l = loss(y_hat, y)\n",
    "        if isinstance(updater, torch.optim.Optimizer):\n",
    "            # 使用PyTorch内置的优化器和损失函数\n",
    "            updater.zero_grad()\n",
    "            l.mean().backward()\n",
    "            updater.step()\n",
    "        else:\n",
    "            # 使用定制的优化器和损失函数\n",
    "            l.sum().backward()\n",
    "            updater(X.shape[0])\n",
    "        metric.add(float(l.sum()), accuracy(y_hat, y), y.numel())\n",
    "    # 返回训练损失和训练精度\n",
    "    return metric[0] / metric[2], metric[1] / metric[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0e70d9-89e7-41e9-b880-1d4801a8abbe",
   "metadata": {},
   "source": [
    "在展示训练函数的实现之前，我们定义一个在动画中绘制数据的实用程序类Animator， 它能够简化本书其余部分的代码。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0a16a7f-084b-4824-90d8-f5b62421aa6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Animator:  #@save\n",
    "    \"\"\"在动画中绘制数据\"\"\"\n",
    "    def __init__(self, xlabel=None, ylabel=None, legend=None, xlim=None,\n",
    "                 ylim=None, xscale='linear', yscale='linear',\n",
    "                 fmts=('-', 'm--', 'g-.', 'r:'), nrows=1, ncols=1,\n",
    "                 figsize=(3.5, 2.5)):\n",
    "        # 增量地绘制多条线\n",
    "        if legend is None:\n",
    "            legend = []\n",
    "        d2l.use_svg_display()\n",
    "        self.fig, self.axes = d2l.plt.subplots(nrows, ncols, figsize=figsize)\n",
    "        if nrows * ncols == 1:\n",
    "            self.axes = [self.axes, ]\n",
    "        # 使用lambda函数捕获参数\n",
    "        self.config_axes = lambda: d2l.set_axes(\n",
    "            self.axes[0], xlabel, ylabel, xlim, ylim, xscale, yscale, legend)\n",
    "        self.X, self.Y, self.fmts = None, None, fmts\n",
    "\n",
    "    def add(self, x, y):\n",
    "        # 向图表中添加多个数据点\n",
    "        if not hasattr(y, \"__len__\"):\n",
    "            y = [y]\n",
    "        n = len(y)\n",
    "        if not hasattr(x, \"__len__\"):\n",
    "            x = [x] * n\n",
    "        if not self.X:\n",
    "            self.X = [[] for _ in range(n)]\n",
    "        if not self.Y:\n",
    "            self.Y = [[] for _ in range(n)]\n",
    "        for i, (a, b) in enumerate(zip(x, y)):\n",
    "            if a is not None and b is not None:\n",
    "                self.X[i].append(a)\n",
    "                self.Y[i].append(b)\n",
    "        self.axes[0].cla()\n",
    "        for x, y, fmt in zip(self.X, self.Y, self.fmts):\n",
    "            self.axes[0].plot(x, y, fmt)\n",
    "        self.config_axes()\n",
    "        display.display(self.fig)\n",
    "        display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f812ff9-45e8-4c2a-9bcf-61f6ea4bb93e",
   "metadata": {},
   "source": [
    "接下来我们实现一个训练函数， 它会在train_iter访问到的训练数据集上训练一个模型net。 该训练函数将会运行多个迭代周期（由num_epochs指定）。 在每个迭代周期结束时，利用test_iter访问到的测试数据集对模型进行评估。 我们将利用Animator类来可视化训练进度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3fc75b5d-cab3-45ec-835a-273b7dd5cc7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_ch3(net, train_iter, test_iter, loss, num_epochs, updater):  #@save\n",
    "    \"\"\"训练模型（定义见第3章）\"\"\"\n",
    "    animator = Animator(xlabel='epoch', xlim=[1, num_epochs], ylim=[0.3, 0.9],\n",
    "                        legend=['train loss', 'train acc', 'test acc'])\n",
    "    for epoch in range(num_epochs):\n",
    "        train_metrics = train_epoch_ch3(net, train_iter, loss, updater)\n",
    "        test_acc = evaluate_accuracy(net, test_iter)\n",
    "        animator.add(epoch + 1, train_metrics + (test_acc,))\n",
    "    train_loss, train_acc = train_metrics\n",
    "    assert train_loss < 0.5, train_loss\n",
    "    assert train_acc <= 1 and train_acc > 0.7, train_acc\n",
    "    assert test_acc <= 1 and test_acc > 0.7, test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceba6957-2709-44a8-92a3-e9716057443a",
   "metadata": {},
   "source": [
    "作为一个从零开始的实现，我们使用 3.2节中定义的 小批量随机梯度下降来优化模型的损失函数，设置学习率为0.1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca3a7577-53da-4eb6-b7b8-48f6a209a180",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr = 0.1\n",
    "\n",
    "def updater(batch_size):\n",
    "    return d2l.sgd([W, b], lr, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea931d4-3d99-4002-acb2-5bd1300a47c1",
   "metadata": {},
   "source": [
    "现在，我们训练模型10个迭代周期。 请注意，迭代周期（num_epochs）和学习率（lr）都是可调节的超参数。 通过更改它们的值，我们可以提高模型的分类精度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b82ed4e-d158-41a6-aca5-b8935ca989a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"238.965625pt\" height=\"183.35625pt\" viewBox=\"0 0 238.965625 183.35625\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2024-06-09T15:51:28.244436</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.5.1, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 183.35625 \n",
       "L 238.965625 183.35625 \n",
       "L 238.965625 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 30.103125 145.8 \n",
       "L 225.403125 145.8 \n",
       "L 225.403125 7.2 \n",
       "L 30.103125 7.2 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <path d=\"M 51.803125 145.8 \n",
       "L 51.803125 7.2 \n",
       "\" clip-path=\"url(#p05c44e9ef3)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_2\">\n",
       "      <defs>\n",
       "       <path id=\"m96d1c054d9\" d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m96d1c054d9\" x=\"51.803125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 2 -->\n",
       "      <g transform=\"translate(48.621875 160.398438)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \n",
       "L 3431 531 \n",
       "L 3431 0 \n",
       "L 469 0 \n",
       "L 469 531 \n",
       "Q 828 903 1448 1529 \n",
       "Q 2069 2156 2228 2338 \n",
       "Q 2531 2678 2651 2914 \n",
       "Q 2772 3150 2772 3378 \n",
       "Q 2772 3750 2511 3984 \n",
       "Q 2250 4219 1831 4219 \n",
       "Q 1534 4219 1204 4116 \n",
       "Q 875 4013 500 3803 \n",
       "L 500 4441 \n",
       "Q 881 4594 1212 4672 \n",
       "Q 1544 4750 1819 4750 \n",
       "Q 2544 4750 2975 4387 \n",
       "Q 3406 4025 3406 3419 \n",
       "Q 3406 3131 3298 2873 \n",
       "Q 3191 2616 2906 2266 \n",
       "Q 2828 2175 2409 1742 \n",
       "Q 1991 1309 1228 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <path d=\"M 95.203125 145.8 \n",
       "L 95.203125 7.2 \n",
       "\" clip-path=\"url(#p05c44e9ef3)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m96d1c054d9\" x=\"95.203125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 4 -->\n",
       "      <g transform=\"translate(92.021875 160.398438)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \n",
       "L 825 1625 \n",
       "L 2419 1625 \n",
       "L 2419 4116 \n",
       "z\n",
       "M 2253 4666 \n",
       "L 3047 4666 \n",
       "L 3047 1625 \n",
       "L 3713 1625 \n",
       "L 3713 1100 \n",
       "L 3047 1100 \n",
       "L 3047 0 \n",
       "L 2419 0 \n",
       "L 2419 1100 \n",
       "L 313 1100 \n",
       "L 313 1709 \n",
       "L 2253 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-34\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <path d=\"M 138.603125 145.8 \n",
       "L 138.603125 7.2 \n",
       "\" clip-path=\"url(#p05c44e9ef3)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m96d1c054d9\" x=\"138.603125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 6 -->\n",
       "      <g transform=\"translate(135.421875 160.398438)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \n",
       "Q 1688 2584 1439 2293 \n",
       "Q 1191 2003 1191 1497 \n",
       "Q 1191 994 1439 701 \n",
       "Q 1688 409 2113 409 \n",
       "Q 2538 409 2786 701 \n",
       "Q 3034 994 3034 1497 \n",
       "Q 3034 2003 2786 2293 \n",
       "Q 2538 2584 2113 2584 \n",
       "z\n",
       "M 3366 4563 \n",
       "L 3366 3988 \n",
       "Q 3128 4100 2886 4159 \n",
       "Q 2644 4219 2406 4219 \n",
       "Q 1781 4219 1451 3797 \n",
       "Q 1122 3375 1075 2522 \n",
       "Q 1259 2794 1537 2939 \n",
       "Q 1816 3084 2150 3084 \n",
       "Q 2853 3084 3261 2657 \n",
       "Q 3669 2231 3669 1497 \n",
       "Q 3669 778 3244 343 \n",
       "Q 2819 -91 2113 -91 \n",
       "Q 1303 -91 875 529 \n",
       "Q 447 1150 447 2328 \n",
       "Q 447 3434 972 4092 \n",
       "Q 1497 4750 2381 4750 \n",
       "Q 2619 4750 2861 4703 \n",
       "Q 3103 4656 3366 4563 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-36\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <path d=\"M 182.003125 145.8 \n",
       "L 182.003125 7.2 \n",
       "\" clip-path=\"url(#p05c44e9ef3)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m96d1c054d9\" x=\"182.003125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 8 -->\n",
       "      <g transform=\"translate(178.821875 160.398438)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \n",
       "Q 1584 2216 1326 1975 \n",
       "Q 1069 1734 1069 1313 \n",
       "Q 1069 891 1326 650 \n",
       "Q 1584 409 2034 409 \n",
       "Q 2484 409 2743 651 \n",
       "Q 3003 894 3003 1313 \n",
       "Q 3003 1734 2745 1975 \n",
       "Q 2488 2216 2034 2216 \n",
       "z\n",
       "M 1403 2484 \n",
       "Q 997 2584 770 2862 \n",
       "Q 544 3141 544 3541 \n",
       "Q 544 4100 942 4425 \n",
       "Q 1341 4750 2034 4750 \n",
       "Q 2731 4750 3128 4425 \n",
       "Q 3525 4100 3525 3541 \n",
       "Q 3525 3141 3298 2862 \n",
       "Q 3072 2584 2669 2484 \n",
       "Q 3125 2378 3379 2068 \n",
       "Q 3634 1759 3634 1313 \n",
       "Q 3634 634 3220 271 \n",
       "Q 2806 -91 2034 -91 \n",
       "Q 1263 -91 848 271 \n",
       "Q 434 634 434 1313 \n",
       "Q 434 1759 690 2068 \n",
       "Q 947 2378 1403 2484 \n",
       "z\n",
       "M 1172 3481 \n",
       "Q 1172 3119 1398 2916 \n",
       "Q 1625 2713 2034 2713 \n",
       "Q 2441 2713 2670 2916 \n",
       "Q 2900 3119 2900 3481 \n",
       "Q 2900 3844 2670 4047 \n",
       "Q 2441 4250 2034 4250 \n",
       "Q 1625 4250 1398 4047 \n",
       "Q 1172 3844 1172 3481 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-38\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <path d=\"M 225.403125 145.8 \n",
       "L 225.403125 7.2 \n",
       "\" clip-path=\"url(#p05c44e9ef3)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m96d1c054d9\" x=\"225.403125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 10 -->\n",
       "      <g transform=\"translate(219.040625 160.398438)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-31\" d=\"M 794 531 \n",
       "L 1825 531 \n",
       "L 1825 4091 \n",
       "L 703 3866 \n",
       "L 703 4441 \n",
       "L 1819 4666 \n",
       "L 2450 4666 \n",
       "L 2450 531 \n",
       "L 3481 531 \n",
       "L 3481 0 \n",
       "L 794 0 \n",
       "L 794 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \n",
       "Q 1547 4250 1301 3770 \n",
       "Q 1056 3291 1056 2328 \n",
       "Q 1056 1369 1301 889 \n",
       "Q 1547 409 2034 409 \n",
       "Q 2525 409 2770 889 \n",
       "Q 3016 1369 3016 2328 \n",
       "Q 3016 3291 2770 3770 \n",
       "Q 2525 4250 2034 4250 \n",
       "z\n",
       "M 2034 4750 \n",
       "Q 2819 4750 3233 4129 \n",
       "Q 3647 3509 3647 2328 \n",
       "Q 3647 1150 3233 529 \n",
       "Q 2819 -91 2034 -91 \n",
       "Q 1250 -91 836 529 \n",
       "Q 422 1150 422 2328 \n",
       "Q 422 3509 836 4129 \n",
       "Q 1250 4750 2034 4750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_6\">\n",
       "     <!-- epoch -->\n",
       "     <g transform=\"translate(112.525 174.076563)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \n",
       "L 3597 1613 \n",
       "L 953 1613 \n",
       "Q 991 1019 1311 708 \n",
       "Q 1631 397 2203 397 \n",
       "Q 2534 397 2845 478 \n",
       "Q 3156 559 3463 722 \n",
       "L 3463 178 \n",
       "Q 3153 47 2828 -22 \n",
       "Q 2503 -91 2169 -91 \n",
       "Q 1331 -91 842 396 \n",
       "Q 353 884 353 1716 \n",
       "Q 353 2575 817 3079 \n",
       "Q 1281 3584 2069 3584 \n",
       "Q 2775 3584 3186 3129 \n",
       "Q 3597 2675 3597 1894 \n",
       "z\n",
       "M 3022 2063 \n",
       "Q 3016 2534 2758 2815 \n",
       "Q 2500 3097 2075 3097 \n",
       "Q 1594 3097 1305 2825 \n",
       "Q 1016 2553 972 2059 \n",
       "L 3022 2063 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \n",
       "L 1159 -1331 \n",
       "L 581 -1331 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2969 \n",
       "Q 1341 3281 1617 3432 \n",
       "Q 1894 3584 2278 3584 \n",
       "Q 2916 3584 3314 3078 \n",
       "Q 3713 2572 3713 1747 \n",
       "Q 3713 922 3314 415 \n",
       "Q 2916 -91 2278 -91 \n",
       "Q 1894 -91 1617 61 \n",
       "Q 1341 213 1159 525 \n",
       "z\n",
       "M 3116 1747 \n",
       "Q 3116 2381 2855 2742 \n",
       "Q 2594 3103 2138 3103 \n",
       "Q 1681 3103 1420 2742 \n",
       "Q 1159 2381 1159 1747 \n",
       "Q 1159 1113 1420 752 \n",
       "Q 1681 391 2138 391 \n",
       "Q 2594 391 2855 752 \n",
       "Q 3116 1113 3116 1747 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \n",
       "Q 1497 3097 1228 2736 \n",
       "Q 959 2375 959 1747 \n",
       "Q 959 1119 1226 758 \n",
       "Q 1494 397 1959 397 \n",
       "Q 2419 397 2687 759 \n",
       "Q 2956 1122 2956 1747 \n",
       "Q 2956 2369 2687 2733 \n",
       "Q 2419 3097 1959 3097 \n",
       "z\n",
       "M 1959 3584 \n",
       "Q 2709 3584 3137 3096 \n",
       "Q 3566 2609 3566 1747 \n",
       "Q 3566 888 3137 398 \n",
       "Q 2709 -91 1959 -91 \n",
       "Q 1206 -91 779 398 \n",
       "Q 353 888 353 1747 \n",
       "Q 353 2609 779 3096 \n",
       "Q 1206 3584 1959 3584 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \n",
       "L 3122 2828 \n",
       "Q 2878 2963 2633 3030 \n",
       "Q 2388 3097 2138 3097 \n",
       "Q 1578 3097 1268 2742 \n",
       "Q 959 2388 959 1747 \n",
       "Q 959 1106 1268 751 \n",
       "Q 1578 397 2138 397 \n",
       "Q 2388 397 2633 464 \n",
       "Q 2878 531 3122 666 \n",
       "L 3122 134 \n",
       "Q 2881 22 2623 -34 \n",
       "Q 2366 -91 2075 -91 \n",
       "Q 1284 -91 818 406 \n",
       "Q 353 903 353 1747 \n",
       "Q 353 2603 823 3093 \n",
       "Q 1294 3584 2113 3584 \n",
       "Q 2378 3584 2631 3529 \n",
       "Q 2884 3475 3122 3366 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \n",
       "L 3513 0 \n",
       "L 2938 0 \n",
       "L 2938 2094 \n",
       "Q 2938 2591 2744 2837 \n",
       "Q 2550 3084 2163 3084 \n",
       "Q 1697 3084 1428 2787 \n",
       "Q 1159 2491 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 4863 \n",
       "L 1159 4863 \n",
       "L 1159 2956 \n",
       "Q 1366 3272 1645 3428 \n",
       "Q 1925 3584 2291 3584 \n",
       "Q 2894 3584 3203 3211 \n",
       "Q 3513 2838 3513 2113 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-65\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-70\" x=\"61.523438\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" x=\"125\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-63\" x=\"186.181641\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-68\" x=\"241.162109\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <path d=\"M 30.103125 122.7 \n",
       "L 225.403125 122.7 \n",
       "\" clip-path=\"url(#p05c44e9ef3)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_12\">\n",
       "      <defs>\n",
       "       <path id=\"m3a2c309f14\" d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m3a2c309f14\" x=\"30.103125\" y=\"122.7\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 0.4 -->\n",
       "      <g transform=\"translate(7.2 126.499219)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \n",
       "L 1344 794 \n",
       "L 1344 0 \n",
       "L 684 0 \n",
       "L 684 794 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-34\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_13\">\n",
       "      <path d=\"M 30.103125 76.5 \n",
       "L 225.403125 76.5 \n",
       "\" clip-path=\"url(#p05c44e9ef3)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_14\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m3a2c309f14\" x=\"30.103125\" y=\"76.5\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 0.6 -->\n",
       "      <g transform=\"translate(7.2 80.299219)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_15\">\n",
       "      <path d=\"M 30.103125 30.3 \n",
       "L 225.403125 30.3 \n",
       "\" clip-path=\"url(#p05c44e9ef3)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_16\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m3a2c309f14\" x=\"30.103125\" y=\"30.3\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 0.8 -->\n",
       "      <g transform=\"translate(7.2 34.099219)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_17\">\n",
       "    <path d=\"M 30.103125 33.072915 \n",
       "L 51.803125 83.370206 \n",
       "L 73.503125 93.743421 \n",
       "L 95.203125 99.275299 \n",
       "L 116.903125 102.829833 \n",
       "L 138.603125 105.841334 \n",
       "L 160.303125 107.563422 \n",
       "L 182.003125 109.301425 \n",
       "L 203.703125 110.835689 \n",
       "L 225.403125 111.639444 \n",
       "\" clip-path=\"url(#p05c44e9ef3)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_18\">\n",
       "    <path d=\"M 30.103125 42.26965 \n",
       "L 51.803125 27.37785 \n",
       "L 73.503125 24.2093 \n",
       "L 95.203125 22.98115 \n",
       "L 116.903125 21.6452 \n",
       "L 138.603125 20.94065 \n",
       "L 160.303125 20.6596 \n",
       "L 182.003125 19.9358 \n",
       "L 203.703125 19.45455 \n",
       "L 225.403125 19.32365 \n",
       "\" clip-path=\"url(#p05c44e9ef3)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #bf00bf; stroke-width: 1.5\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_19\">\n",
       "    <path d=\"M 30.103125 45.3381 \n",
       "L 51.803125 28.4289 \n",
       "L 73.503125 27.1122 \n",
       "L 95.203125 29.8149 \n",
       "L 116.903125 25.911 \n",
       "L 138.603125 26.6733 \n",
       "L 160.303125 23.2314 \n",
       "L 182.003125 23.6241 \n",
       "L 203.703125 22.4922 \n",
       "L 225.403125 22.8387 \n",
       "\" clip-path=\"url(#p05c44e9ef3)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 30.103125 145.8 \n",
       "L 30.103125 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 225.403125 145.8 \n",
       "L 225.403125 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 30.103125 145.8 \n",
       "L 225.403125 145.8 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 30.103125 7.2 \n",
       "L 225.403125 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"legend_1\">\n",
       "    <g id=\"patch_7\">\n",
       "     <path d=\"M 140.634375 100.017188 \n",
       "L 218.403125 100.017188 \n",
       "Q 220.403125 100.017188 220.403125 98.017188 \n",
       "L 220.403125 54.982812 \n",
       "Q 220.403125 52.982812 218.403125 52.982812 \n",
       "L 140.634375 52.982812 \n",
       "Q 138.634375 52.982812 138.634375 54.982812 \n",
       "L 138.634375 98.017188 \n",
       "Q 138.634375 100.017188 140.634375 100.017188 \n",
       "z\n",
       "\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_20\">\n",
       "     <path d=\"M 142.634375 61.08125 \n",
       "L 152.634375 61.08125 \n",
       "L 162.634375 61.08125 \n",
       "\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "    </g>\n",
       "    <g id=\"text_10\">\n",
       "     <!-- train loss -->\n",
       "     <g transform=\"translate(170.634375 64.58125)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \n",
       "L 1172 3500 \n",
       "L 2356 3500 \n",
       "L 2356 3053 \n",
       "L 1172 3053 \n",
       "L 1172 1153 \n",
       "Q 1172 725 1289 603 \n",
       "Q 1406 481 1766 481 \n",
       "L 2356 481 \n",
       "L 2356 0 \n",
       "L 1766 0 \n",
       "Q 1100 0 847 248 \n",
       "Q 594 497 594 1153 \n",
       "L 594 3053 \n",
       "L 172 3053 \n",
       "L 172 3500 \n",
       "L 594 3500 \n",
       "L 594 4494 \n",
       "L 1172 4494 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \n",
       "Q 2534 3019 2420 3045 \n",
       "Q 2306 3072 2169 3072 \n",
       "Q 1681 3072 1420 2755 \n",
       "Q 1159 2438 1159 1844 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1341 3275 1631 3429 \n",
       "Q 1922 3584 2338 3584 \n",
       "Q 2397 3584 2469 3576 \n",
       "Q 2541 3569 2628 3553 \n",
       "L 2631 2963 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \n",
       "Q 1497 1759 1228 1600 \n",
       "Q 959 1441 959 1056 \n",
       "Q 959 750 1161 570 \n",
       "Q 1363 391 1709 391 \n",
       "Q 2188 391 2477 730 \n",
       "Q 2766 1069 2766 1631 \n",
       "L 2766 1759 \n",
       "L 2194 1759 \n",
       "z\n",
       "M 3341 1997 \n",
       "L 3341 0 \n",
       "L 2766 0 \n",
       "L 2766 531 \n",
       "Q 2569 213 2275 61 \n",
       "Q 1981 -91 1556 -91 \n",
       "Q 1019 -91 701 211 \n",
       "Q 384 513 384 1019 \n",
       "Q 384 1609 779 1909 \n",
       "Q 1175 2209 1959 2209 \n",
       "L 2766 2209 \n",
       "L 2766 2266 \n",
       "Q 2766 2663 2505 2880 \n",
       "Q 2244 3097 1772 3097 \n",
       "Q 1472 3097 1187 3025 \n",
       "Q 903 2953 641 2809 \n",
       "L 641 3341 \n",
       "Q 956 3463 1253 3523 \n",
       "Q 1550 3584 1831 3584 \n",
       "Q 2591 3584 2966 3190 \n",
       "Q 3341 2797 3341 1997 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \n",
       "L 1178 3500 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 3500 \n",
       "z\n",
       "M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 4134 \n",
       "L 603 4134 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \n",
       "L 3513 0 \n",
       "L 2938 0 \n",
       "L 2938 2094 \n",
       "Q 2938 2591 2744 2837 \n",
       "Q 2550 3084 2163 3084 \n",
       "Q 1697 3084 1428 2787 \n",
       "Q 1159 2491 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1366 3272 1645 3428 \n",
       "Q 1925 3584 2291 3584 \n",
       "Q 2894 3584 3203 3211 \n",
       "Q 3513 2838 3513 2113 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \n",
       "L 2834 2853 \n",
       "Q 2591 2978 2328 3040 \n",
       "Q 2066 3103 1784 3103 \n",
       "Q 1356 3103 1142 2972 \n",
       "Q 928 2841 928 2578 \n",
       "Q 928 2378 1081 2264 \n",
       "Q 1234 2150 1697 2047 \n",
       "L 1894 2003 \n",
       "Q 2506 1872 2764 1633 \n",
       "Q 3022 1394 3022 966 \n",
       "Q 3022 478 2636 193 \n",
       "Q 2250 -91 1575 -91 \n",
       "Q 1294 -91 989 -36 \n",
       "Q 684 19 347 128 \n",
       "L 347 722 \n",
       "Q 666 556 975 473 \n",
       "Q 1284 391 1588 391 \n",
       "Q 1994 391 2212 530 \n",
       "Q 2431 669 2431 922 \n",
       "Q 2431 1156 2273 1281 \n",
       "Q 2116 1406 1581 1522 \n",
       "L 1381 1569 \n",
       "Q 847 1681 609 1914 \n",
       "Q 372 2147 372 2553 \n",
       "Q 372 3047 722 3315 \n",
       "Q 1072 3584 1716 3584 \n",
       "Q 2034 3584 2315 3537 \n",
       "Q 2597 3491 2834 3397 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-74\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-72\" x=\"39.208984\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" x=\"80.322266\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-69\" x=\"141.601562\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6e\" x=\"169.384766\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-20\" x=\"232.763672\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6c\" x=\"264.550781\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" x=\"292.333984\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" x=\"353.515625\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" x=\"405.615234\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_21\">\n",
       "     <path d=\"M 142.634375 75.759375 \n",
       "L 152.634375 75.759375 \n",
       "L 162.634375 75.759375 \n",
       "\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #bf00bf; stroke-width: 1.5\"/>\n",
       "    </g>\n",
       "    <g id=\"text_11\">\n",
       "     <!-- train acc -->\n",
       "     <g transform=\"translate(170.634375 79.259375)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-74\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-72\" x=\"39.208984\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" x=\"80.322266\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-69\" x=\"141.601562\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6e\" x=\"169.384766\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-20\" x=\"232.763672\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" x=\"264.550781\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-63\" x=\"325.830078\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-63\" x=\"380.810547\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_22\">\n",
       "     <path d=\"M 142.634375 90.4375 \n",
       "L 152.634375 90.4375 \n",
       "L 162.634375 90.4375 \n",
       "\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n",
       "    </g>\n",
       "    <g id=\"text_12\">\n",
       "     <!-- test acc -->\n",
       "     <g transform=\"translate(170.634375 93.9375)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-74\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-65\" x=\"39.208984\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" x=\"100.732422\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-74\" x=\"152.832031\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-20\" x=\"192.041016\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" x=\"223.828125\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-63\" x=\"285.107422\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-63\" x=\"340.087891\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p05c44e9ef3\">\n",
       "   <rect x=\"30.103125\" y=\"7.2\" width=\"195.3\" height=\"138.6\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 350x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "train_ch3(net, train_iter, test_iter, cross_entropy, num_epochs, updater)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d32069-25ef-4109-96ad-92ecc0e53a73",
   "metadata": {},
   "source": [
    "## 预测\n",
    "现在训练已经完成，我们的模型已经准备好对图像进行分类预测。 给定一系列图像，我们将比较它们的实际标签（文本输出的第一行）和模型预测（文本输出的第二行）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07db4fff-275d-4d7e-900e-00b6e7407e9c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"520.1pt\" height=\"118.198357pt\" viewBox=\"0 0 520.1 118.198357\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2024-06-09T15:51:30.928550</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.5.1, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 118.198357 \n",
       "L 520.1 118.198357 \n",
       "L 520.1 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 10.7 107.498357 \n",
       "L 82.442857 107.498357 \n",
       "L 82.442857 35.7555 \n",
       "L 10.7 35.7555 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g clip-path=\"url(#p2c45364fe9)\">\n",
       "    <image xlink:href=\"data:image/png;base64,\n",
       "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\" id=\"image17ea069f4e\" transform=\"scale(1 -1)translate(0 -72)\" x=\"10.7\" y=\"-35.498357\" width=\"72\" height=\"72\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 10.7 107.498357 \n",
       "L 10.7 35.7555 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 82.442857 107.498357 \n",
       "L 82.442857 35.7555 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 10.7 107.498357 \n",
       "L 82.442857 107.498357 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 10.7 35.7555 \n",
       "L 82.442857 35.7555 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"text_1\">\n",
       "    <!-- ankle boot -->\n",
       "    <g transform=\"translate(14.848304 16.318125)scale(0.12 -0.12)\">\n",
       "     <defs>\n",
       "      <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \n",
       "Q 1497 1759 1228 1600 \n",
       "Q 959 1441 959 1056 \n",
       "Q 959 750 1161 570 \n",
       "Q 1363 391 1709 391 \n",
       "Q 2188 391 2477 730 \n",
       "Q 2766 1069 2766 1631 \n",
       "L 2766 1759 \n",
       "L 2194 1759 \n",
       "z\n",
       "M 3341 1997 \n",
       "L 3341 0 \n",
       "L 2766 0 \n",
       "L 2766 531 \n",
       "Q 2569 213 2275 61 \n",
       "Q 1981 -91 1556 -91 \n",
       "Q 1019 -91 701 211 \n",
       "Q 384 513 384 1019 \n",
       "Q 384 1609 779 1909 \n",
       "Q 1175 2209 1959 2209 \n",
       "L 2766 2209 \n",
       "L 2766 2266 \n",
       "Q 2766 2663 2505 2880 \n",
       "Q 2244 3097 1772 3097 \n",
       "Q 1472 3097 1187 3025 \n",
       "Q 903 2953 641 2809 \n",
       "L 641 3341 \n",
       "Q 956 3463 1253 3523 \n",
       "Q 1550 3584 1831 3584 \n",
       "Q 2591 3584 2966 3190 \n",
       "Q 3341 2797 3341 1997 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \n",
       "L 3513 0 \n",
       "L 2938 0 \n",
       "L 2938 2094 \n",
       "Q 2938 2591 2744 2837 \n",
       "Q 2550 3084 2163 3084 \n",
       "Q 1697 3084 1428 2787 \n",
       "Q 1159 2491 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1366 3272 1645 3428 \n",
       "Q 1925 3584 2291 3584 \n",
       "Q 2894 3584 3203 3211 \n",
       "Q 3513 2838 3513 2113 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-6b\" d=\"M 581 4863 \n",
       "L 1159 4863 \n",
       "L 1159 1991 \n",
       "L 2875 3500 \n",
       "L 3609 3500 \n",
       "L 1753 1863 \n",
       "L 3688 0 \n",
       "L 2938 0 \n",
       "L 1159 1709 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \n",
       "L 3597 1613 \n",
       "L 953 1613 \n",
       "Q 991 1019 1311 708 \n",
       "Q 1631 397 2203 397 \n",
       "Q 2534 397 2845 478 \n",
       "Q 3156 559 3463 722 \n",
       "L 3463 178 \n",
       "Q 3153 47 2828 -22 \n",
       "Q 2503 -91 2169 -91 \n",
       "Q 1331 -91 842 396 \n",
       "Q 353 884 353 1716 \n",
       "Q 353 2575 817 3079 \n",
       "Q 1281 3584 2069 3584 \n",
       "Q 2775 3584 3186 3129 \n",
       "Q 3597 2675 3597 1894 \n",
       "z\n",
       "M 3022 2063 \n",
       "Q 3016 2534 2758 2815 \n",
       "Q 2500 3097 2075 3097 \n",
       "Q 1594 3097 1305 2825 \n",
       "Q 1016 2553 972 2059 \n",
       "L 3022 2063 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-62\" d=\"M 3116 1747 \n",
       "Q 3116 2381 2855 2742 \n",
       "Q 2594 3103 2138 3103 \n",
       "Q 1681 3103 1420 2742 \n",
       "Q 1159 2381 1159 1747 \n",
       "Q 1159 1113 1420 752 \n",
       "Q 1681 391 2138 391 \n",
       "Q 2594 391 2855 752 \n",
       "Q 3116 1113 3116 1747 \n",
       "z\n",
       "M 1159 2969 \n",
       "Q 1341 3281 1617 3432 \n",
       "Q 1894 3584 2278 3584 \n",
       "Q 2916 3584 3314 3078 \n",
       "Q 3713 2572 3713 1747 \n",
       "Q 3713 922 3314 415 \n",
       "Q 2916 -91 2278 -91 \n",
       "Q 1894 -91 1617 61 \n",
       "Q 1341 213 1159 525 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 4863 \n",
       "L 1159 4863 \n",
       "L 1159 2969 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \n",
       "Q 1497 3097 1228 2736 \n",
       "Q 959 2375 959 1747 \n",
       "Q 959 1119 1226 758 \n",
       "Q 1494 397 1959 397 \n",
       "Q 2419 397 2687 759 \n",
       "Q 2956 1122 2956 1747 \n",
       "Q 2956 2369 2687 2733 \n",
       "Q 2419 3097 1959 3097 \n",
       "z\n",
       "M 1959 3584 \n",
       "Q 2709 3584 3137 3096 \n",
       "Q 3566 2609 3566 1747 \n",
       "Q 3566 888 3137 398 \n",
       "Q 2709 -91 1959 -91 \n",
       "Q 1206 -91 779 398 \n",
       "Q 353 888 353 1747 \n",
       "Q 353 2609 779 3096 \n",
       "Q 1206 3584 1959 3584 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \n",
       "L 1172 3500 \n",
       "L 2356 3500 \n",
       "L 2356 3053 \n",
       "L 1172 3053 \n",
       "L 1172 1153 \n",
       "Q 1172 725 1289 603 \n",
       "Q 1406 481 1766 481 \n",
       "L 2356 481 \n",
       "L 2356 0 \n",
       "L 1766 0 \n",
       "Q 1100 0 847 248 \n",
       "Q 594 497 594 1153 \n",
       "L 594 3053 \n",
       "L 172 3053 \n",
       "L 172 3500 \n",
       "L 594 3500 \n",
       "L 594 4494 \n",
       "L 1172 4494 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#DejaVuSans-61\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6e\" x=\"61.279297\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6b\" x=\"124.658203\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6c\" x=\"182.568359\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-65\" x=\"210.351562\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-20\" x=\"271.875\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-62\" x=\"303.662109\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6f\" x=\"367.138672\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6f\" x=\"428.320312\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-74\" x=\"489.501953\"/>\n",
       "    </g>\n",
       "    <!-- ankle boot -->\n",
       "    <g transform=\"translate(14.848304 29.7555)scale(0.12 -0.12)\">\n",
       "     <use xlink:href=\"#DejaVuSans-61\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6e\" x=\"61.279297\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6b\" x=\"124.658203\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6c\" x=\"182.568359\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-65\" x=\"210.351562\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-20\" x=\"271.875\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-62\" x=\"303.662109\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6f\" x=\"367.138672\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6f\" x=\"428.320312\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-74\" x=\"489.501953\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       "  <g id=\"axes_2\">\n",
       "   <g id=\"patch_7\">\n",
       "    <path d=\"M 96.791429 107.498357 \n",
       "L 168.534286 107.498357 \n",
       "L 168.534286 35.7555 \n",
       "L 96.791429 35.7555 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g clip-path=\"url(#p22d63f10d7)\">\n",
       "    <image xlink:href=\"data:image/png;base64,\n",
       "iVBORw0KGgoAAAANSUhEUgAAAGQAAABkCAYAAABw4pVUAAAJCUlEQVR4nO2dXWwc1RXH78zsetfrz9gB59vESlIkSIggifkqIg2FBCpoKxQZhET4euLrARWkSjwgIbV9KfACLanUEglVVFGRQFDCZzBtAypUgSQOTjBgO4nt2AnrrLPe3dmZ4QXm3v8xd2xfDLqyzu/pHp2ZO2OfueeeOXPuXeca5+ZIGBBcfTHIVzz1Qdw+VakH3ec/z+K5+fG47aRrQBdVfSk4rsmtfS8c11HupYq6VArk4ivL4/ay+jzoBp5YE7frdn8gZsqP/xczibBBLIMNYhmp6Q/5bgrLMyA/ds6huD0eToLu1qbteLIyh0R+RX+RKDC9PWOiMEG5/nwQX75gZ9xucmtBt3qTPLZj98yvzyPEMtgglmHsskY3YLQ8VJ2I2yUaSLvzw+5OBcPg04F0qYVwAnTVejN3Oz/+U/MINohlsEEsw3gO2bThCMiFSKYclnge6ta1gXznv/bF7R2NJ0H3fKE1bqcd9NlJeEKfAfIcjGUrkby/Yojhu3o/a969HXSrHi+BvDItU0T7y2XQdV70Wdz+SntnU+ERYhlsEMswdlmnSnUgZx3pMupdzO66FXQnG7P9cbvPx/BwfQbf8nUEwgE5jFB2Hb0LyzrymqUI3WsQyezz0oV50JUXLdT2mXHw79h/fGncbhentedReIRYBhvEMtgglmE8h9SmfJDbvIzmSCHKD6APbfNkGNrr50CXdvQphzDSPz90TkkL2Q89r+R4Wl1fVc5h97W/A7qHf3Gr9vpZElpXfbN/LY8Qy2CDWIaxy6pP4ZtpEClhJnoPcSqPRQ8jgXwO6Bt2jZBDv0KeF9Wd0fOoy1JDW5/0ox7rk/PWpGU43/XxNtAleFPhkb85mPS++8Bp4BFiGWwQy2CDWIbxHJLxMBM7FspihRUuFr+5RzG0zXfKEPkcD1Mlo4EsFsjOIttL5xAq6yhF6Sk9fUt+sBk0bReMglyOZOg/5cmumj3rPEIsgw1iGWwQyzBPnXiYOilFep/t+qj7/+TKuH1HUy/oBqvSp89mDkn6YkhJK2mOpDmk/SV88bjs90fxSOXdi751pPP8HjIvYINYhrHLakmfBTmb8IWOJmlfGLwkbt+/oB90fmR8S6Qf/bOWUdxS1vG1x+UOngD5qgZ0rxNK2Jtz0UV5xZmF3RQeIZbBBrEMNohlGDvsyQDDxayj95mVVZgeOT60QArr8NizoZpWKYBupukQCj1PTcfXOXR9ipwLKh1Y4Lc1h58cDleU4kDynyRT7IzhEWIZbBDLMHZZ5RBdVpJlN3ZgaPvxnvM1R2Idrk+K2FxFZ+q+hMDiuBYP63X9SBb5FRfrCzeEEKIcqcUS+FZfO2q02pxHiG2wQSyDDWIZxnPI5xOtIC8gy4JVlmbzIA9+ql97nHNkaEnnCfXpma7qRIUWwyVVrxz2ZTokIYE95Zo+6ad2dOaZahUeIZbBBrEMY5d1bLwJZE/ZuUddIi2EEBvrvwB574JObb+NbkmrU93LbFyWS+puS0pG2RX4pp4PZdh7cqO2yyn3cK6H62WckMPeeQEbxDLYIJZhPIdMjOvD3P4q6rbV4Ze3XV0ylTJA5pt8KMNpWoDQ7Bbjds7FzCtd3qzSQOalvHLsaVJIMVyVc+OOa/dq+5yO7LBM9yZtMEThEWIZbBDLYINYhvEc4o7VTH/QN9Dd1p5fJbdY6/VRh1/lcJ444ku/rBZlCyFER/qM9vpfVnHB0JVZ2U+OFIZfkpG73QV1uCnGQLUIctrRF8NFh45qdUnwCLEMNohlmNf2juhtSZc2+ySLcFbZaXJJCgsgOv75UNyOUnjiPZe/G7d/uxCL1n4z/FOQz8uOxe17mwdBt3dSpkf+sPZSvLcXZWFD99oXQZdUv0yhmzDPFB4hlsEGsQw2iGUYzyHZhKqKNEl3l8nuxEXFF6vrwoUQYvV9+o3ruzfIfPiuhzeBrn37AZA/ETIF4/Xg9Z/5801xe1kLVsScOKgUx63F69OtnNJKUmQi1H82mA08QiyDDWIZxi6rYVC/Zzvd3U2Qr3vqJpnddKQr6yz2HPsIVDd0Lovb7duPge6OXnQ9XQ3yLZtuUPmPw/Le//LfF0D3u5Ob4zbNRHtk4VqzK13WnuIiMRfwCLEMNohlsEEswzzsHZqY/qBvKISYRlicktnX18+Q2DLU74E0slX+5lPrTpxD/tZ1Pci7ziqTU4qEqz0fxu27r74NdNG4zBqvOIBZYjoX5ZTH+b3CGoFw6mRewAaxDGOXFfX1a3X0TT0fot0XK+19YytBlxID2n4/fOyZuH3dzvWgO7KjAe+h0Bi3V+zB2Lr0a1moVzuEOrcJMwcz5a0BdFlLRI9RPzxCLIMNYhlsEMswnkPCkj67SecQWpCgkrkFvxgm/XLTJxV5zbZ9jai87H3teTf2nAJZ/YJ4/dqfge7oIz/R9kN3Sc0qBeb+gSZ6uBE8QiyDDWIZbBDLmJu9kIQQXwWyiGzqYhq93Xv/uAzkjmelXI7+B7rhqnzX2NXeDbov+jGV80ZRvhdcUdsHuv+UZLH1qwfeBt3rxffitvp7WEIIsbpmGGRfWZu+5N/6bZ5mA48Qy2CDWMacuaxeX785Mt0io7skh3rflr9iR1tk8xD5qdOsK93Ca0VcD7KcFNz9sl7W1u4vN4OuRinke62Ia1BaPOn6Wj3c0icfYvg+Esg64NqeIdCZ5Xp5hFgHG8Qy2CCW4Vzj3Gy2oJpw/JHL4/bBB58GHa0sKSlbO4XkmXCV4jO6Zn3qpseSKZvxK9tp1JH1iHgeXl9dq0ivty2H60Vu/PRXUtiCXzBN4RFiGWwQy5gzl6Vy5E9Yd/vq1idB7khLVzASoDsZDqTLKIT4E66LlJC0ycW8cA3ZhDOvJJxPVMnXRGUpdAtxi4uUCD3j4FvBg8c3gzzQabjTZQI8QiyDDWIZbBDL+EHmEIpbh5UcfY/K3ZPvuuFN0F1YK7/mdWbwS9+JQDr4dTU4vyQxFqCvV39Hka75eKC3K26Hz50Lusa/679KzhU8QiyDDWIZP4rLmg1ea0vcPrN5NejqduuXuyURbL4Y5NQZGWpHHx0y6vOHgkeIZbBBLIMNYhlfA778lLHwiudmAAAAAElFTkSuQmCC\" id=\"imagea8407ff746\" transform=\"scale(1 -1)translate(0 -72)\" x=\"96.791429\" y=\"-35.498357\" width=\"72\" height=\"72\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_8\">\n",
       "    <path d=\"M 96.791429 107.498357 \n",
       "L 96.791429 35.7555 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_9\">\n",
       "    <path d=\"M 168.534286 107.498357 \n",
       "L 168.534286 35.7555 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_10\">\n",
       "    <path d=\"M 96.791429 107.498357 \n",
       "L 168.534286 107.498357 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_11\">\n",
       "    <path d=\"M 96.791429 35.7555 \n",
       "L 168.534286 35.7555 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"text_2\">\n",
       "    <!-- pullover -->\n",
       "    <g transform=\"translate(108.336607 16.318125)scale(0.12 -0.12)\">\n",
       "     <defs>\n",
       "      <path id=\"DejaVuSans-70\" d=\"M 1159 525 \n",
       "L 1159 -1331 \n",
       "L 581 -1331 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2969 \n",
       "Q 1341 3281 1617 3432 \n",
       "Q 1894 3584 2278 3584 \n",
       "Q 2916 3584 3314 3078 \n",
       "Q 3713 2572 3713 1747 \n",
       "Q 3713 922 3314 415 \n",
       "Q 2916 -91 2278 -91 \n",
       "Q 1894 -91 1617 61 \n",
       "Q 1341 213 1159 525 \n",
       "z\n",
       "M 3116 1747 \n",
       "Q 3116 2381 2855 2742 \n",
       "Q 2594 3103 2138 3103 \n",
       "Q 1681 3103 1420 2742 \n",
       "Q 1159 2381 1159 1747 \n",
       "Q 1159 1113 1420 752 \n",
       "Q 1681 391 2138 391 \n",
       "Q 2594 391 2855 752 \n",
       "Q 3116 1113 3116 1747 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-75\" d=\"M 544 1381 \n",
       "L 544 3500 \n",
       "L 1119 3500 \n",
       "L 1119 1403 \n",
       "Q 1119 906 1312 657 \n",
       "Q 1506 409 1894 409 \n",
       "Q 2359 409 2629 706 \n",
       "Q 2900 1003 2900 1516 \n",
       "L 2900 3500 \n",
       "L 3475 3500 \n",
       "L 3475 0 \n",
       "L 2900 0 \n",
       "L 2900 538 \n",
       "Q 2691 219 2414 64 \n",
       "Q 2138 -91 1772 -91 \n",
       "Q 1169 -91 856 284 \n",
       "Q 544 659 544 1381 \n",
       "z\n",
       "M 1991 3584 \n",
       "L 1991 3584 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-76\" d=\"M 191 3500 \n",
       "L 800 3500 \n",
       "L 1894 563 \n",
       "L 2988 3500 \n",
       "L 3597 3500 \n",
       "L 2284 0 \n",
       "L 1503 0 \n",
       "L 191 3500 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \n",
       "Q 2534 3019 2420 3045 \n",
       "Q 2306 3072 2169 3072 \n",
       "Q 1681 3072 1420 2755 \n",
       "Q 1159 2438 1159 1844 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1341 3275 1631 3429 \n",
       "Q 1922 3584 2338 3584 \n",
       "Q 2397 3584 2469 3576 \n",
       "Q 2541 3569 2628 3553 \n",
       "L 2631 2963 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#DejaVuSans-70\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-75\" x=\"63.476562\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6c\" x=\"126.855469\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6c\" x=\"154.638672\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6f\" x=\"182.421875\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-76\" x=\"243.603516\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-65\" x=\"302.783203\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-72\" x=\"364.306641\"/>\n",
       "    </g>\n",
       "    <!-- pullover -->\n",
       "    <g transform=\"translate(108.336607 29.7555)scale(0.12 -0.12)\">\n",
       "     <use xlink:href=\"#DejaVuSans-70\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-75\" x=\"63.476562\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6c\" x=\"126.855469\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6c\" x=\"154.638672\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6f\" x=\"182.421875\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-76\" x=\"243.603516\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-65\" x=\"302.783203\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-72\" x=\"364.306641\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       "  <g id=\"axes_3\">\n",
       "   <g id=\"patch_12\">\n",
       "    <path d=\"M 182.882857 107.498357 \n",
       "L 254.625714 107.498357 \n",
       "L 254.625714 35.7555 \n",
       "L 182.882857 35.7555 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g clip-path=\"url(#pb13de5ccd3)\">\n",
       "    <image xlink:href=\"data:image/png;base64,\n",
       "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\" id=\"image1ea8cfa6b0\" transform=\"scale(1 -1)translate(0 -72)\" x=\"182.882857\" y=\"-35.498357\" width=\"72\" height=\"72\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_13\">\n",
       "    <path d=\"M 182.882857 107.498357 \n",
       "L 182.882857 35.7555 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_14\">\n",
       "    <path d=\"M 254.625714 107.498357 \n",
       "L 254.625714 35.7555 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_15\">\n",
       "    <path d=\"M 182.882857 107.498357 \n",
       "L 254.625714 107.498357 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_16\">\n",
       "    <path d=\"M 182.882857 35.7555 \n",
       "L 254.625714 35.7555 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"text_3\">\n",
       "    <!-- trouser -->\n",
       "    <g transform=\"translate(197.312723 16.318125)scale(0.12 -0.12)\">\n",
       "     <defs>\n",
       "      <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \n",
       "L 2834 2853 \n",
       "Q 2591 2978 2328 3040 \n",
       "Q 2066 3103 1784 3103 \n",
       "Q 1356 3103 1142 2972 \n",
       "Q 928 2841 928 2578 \n",
       "Q 928 2378 1081 2264 \n",
       "Q 1234 2150 1697 2047 \n",
       "L 1894 2003 \n",
       "Q 2506 1872 2764 1633 \n",
       "Q 3022 1394 3022 966 \n",
       "Q 3022 478 2636 193 \n",
       "Q 2250 -91 1575 -91 \n",
       "Q 1294 -91 989 -36 \n",
       "Q 684 19 347 128 \n",
       "L 347 722 \n",
       "Q 666 556 975 473 \n",
       "Q 1284 391 1588 391 \n",
       "Q 1994 391 2212 530 \n",
       "Q 2431 669 2431 922 \n",
       "Q 2431 1156 2273 1281 \n",
       "Q 2116 1406 1581 1522 \n",
       "L 1381 1569 \n",
       "Q 847 1681 609 1914 \n",
       "Q 372 2147 372 2553 \n",
       "Q 372 3047 722 3315 \n",
       "Q 1072 3584 1716 3584 \n",
       "Q 2034 3584 2315 3537 \n",
       "Q 2597 3491 2834 3397 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#DejaVuSans-74\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-72\" x=\"39.208984\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6f\" x=\"78.072266\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-75\" x=\"139.253906\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-73\" x=\"202.632812\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-65\" x=\"254.732422\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-72\" x=\"316.255859\"/>\n",
       "    </g>\n",
       "    <!-- trouser -->\n",
       "    <g transform=\"translate(197.312723 29.7555)scale(0.12 -0.12)\">\n",
       "     <use xlink:href=\"#DejaVuSans-74\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-72\" x=\"39.208984\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6f\" x=\"78.072266\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-75\" x=\"139.253906\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-73\" x=\"202.632812\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-65\" x=\"254.732422\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-72\" x=\"316.255859\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       "  <g id=\"axes_4\">\n",
       "   <g id=\"patch_17\">\n",
       "    <path d=\"M 268.974286 107.498357 \n",
       "L 340.717143 107.498357 \n",
       "L 340.717143 35.7555 \n",
       "L 268.974286 35.7555 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g clip-path=\"url(#p50336d2915)\">\n",
       "    <image xlink:href=\"data:image/png;base64,\n",
       "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\" id=\"imageac82bdea37\" transform=\"scale(1 -1)translate(0 -72)\" x=\"268.974286\" y=\"-35.498357\" width=\"72\" height=\"72\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_18\">\n",
       "    <path d=\"M 268.974286 107.498357 \n",
       "L 268.974286 35.7555 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_19\">\n",
       "    <path d=\"M 340.717143 107.498357 \n",
       "L 340.717143 35.7555 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_20\">\n",
       "    <path d=\"M 268.974286 107.498357 \n",
       "L 340.717143 107.498357 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_21\">\n",
       "    <path d=\"M 268.974286 35.7555 \n",
       "L 340.717143 35.7555 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"text_4\">\n",
       "    <!-- trouser -->\n",
       "    <g transform=\"translate(283.404152 16.318125)scale(0.12 -0.12)\">\n",
       "     <use xlink:href=\"#DejaVuSans-74\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-72\" x=\"39.208984\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6f\" x=\"78.072266\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-75\" x=\"139.253906\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-73\" x=\"202.632812\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-65\" x=\"254.732422\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-72\" x=\"316.255859\"/>\n",
       "    </g>\n",
       "    <!-- trouser -->\n",
       "    <g transform=\"translate(283.404152 29.7555)scale(0.12 -0.12)\">\n",
       "     <use xlink:href=\"#DejaVuSans-74\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-72\" x=\"39.208984\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6f\" x=\"78.072266\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-75\" x=\"139.253906\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-73\" x=\"202.632812\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-65\" x=\"254.732422\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-72\" x=\"316.255859\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       "  <g id=\"axes_5\">\n",
       "   <g id=\"patch_22\">\n",
       "    <path d=\"M 355.065714 107.498357 \n",
       "L 426.808571 107.498357 \n",
       "L 426.808571 35.7555 \n",
       "L 355.065714 35.7555 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g clip-path=\"url(#p98f307e631)\">\n",
       "    <image xlink:href=\"data:image/png;base64,\n",
       "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\" id=\"image98685ffb40\" transform=\"scale(1 -1)translate(0 -72)\" x=\"355.065714\" y=\"-35.498357\" width=\"72\" height=\"72\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_23\">\n",
       "    <path d=\"M 355.065714 107.498357 \n",
       "L 355.065714 35.7555 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_24\">\n",
       "    <path d=\"M 426.808571 107.498357 \n",
       "L 426.808571 35.7555 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_25\">\n",
       "    <path d=\"M 355.065714 107.498357 \n",
       "L 426.808571 107.498357 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_26\">\n",
       "    <path d=\"M 355.065714 35.7555 \n",
       "L 426.808571 35.7555 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"text_5\">\n",
       "    <!-- shirt -->\n",
       "    <g transform=\"translate(377.523393 16.318125)scale(0.12 -0.12)\">\n",
       "     <defs>\n",
       "      <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \n",
       "L 3513 0 \n",
       "L 2938 0 \n",
       "L 2938 2094 \n",
       "Q 2938 2591 2744 2837 \n",
       "Q 2550 3084 2163 3084 \n",
       "Q 1697 3084 1428 2787 \n",
       "Q 1159 2491 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 4863 \n",
       "L 1159 4863 \n",
       "L 1159 2956 \n",
       "Q 1366 3272 1645 3428 \n",
       "Q 1925 3584 2291 3584 \n",
       "Q 2894 3584 3203 3211 \n",
       "Q 3513 2838 3513 2113 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-69\" d=\"M 603 3500 \n",
       "L 1178 3500 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 3500 \n",
       "z\n",
       "M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 4134 \n",
       "L 603 4134 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#DejaVuSans-73\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-68\" x=\"52.099609\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-69\" x=\"115.478516\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-72\" x=\"143.261719\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-74\" x=\"184.375\"/>\n",
       "    </g>\n",
       "    <!-- shirt -->\n",
       "    <g transform=\"translate(377.523393 29.7555)scale(0.12 -0.12)\">\n",
       "     <use xlink:href=\"#DejaVuSans-73\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-68\" x=\"52.099609\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-69\" x=\"115.478516\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-72\" x=\"143.261719\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-74\" x=\"184.375\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       "  <g id=\"axes_6\">\n",
       "   <g id=\"patch_27\">\n",
       "    <path d=\"M 441.157143 107.498357 \n",
       "L 512.9 107.498357 \n",
       "L 512.9 35.7555 \n",
       "L 441.157143 35.7555 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g clip-path=\"url(#p0fffecee77)\">\n",
       "    <image xlink:href=\"data:image/png;base64,\n",
       "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\" id=\"image0352d6be98\" transform=\"scale(1 -1)translate(0 -72)\" x=\"441.157143\" y=\"-35.498357\" width=\"72\" height=\"72\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_28\">\n",
       "    <path d=\"M 441.157143 107.498357 \n",
       "L 441.157143 35.7555 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_29\">\n",
       "    <path d=\"M 512.9 107.498357 \n",
       "L 512.9 35.7555 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_30\">\n",
       "    <path d=\"M 441.157143 107.498357 \n",
       "L 512.9 107.498357 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_31\">\n",
       "    <path d=\"M 441.157143 35.7555 \n",
       "L 512.9 35.7555 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"text_6\">\n",
       "    <!-- trouser -->\n",
       "    <g transform=\"translate(455.587009 16.318125)scale(0.12 -0.12)\">\n",
       "     <use xlink:href=\"#DejaVuSans-74\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-72\" x=\"39.208984\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6f\" x=\"78.072266\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-75\" x=\"139.253906\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-73\" x=\"202.632812\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-65\" x=\"254.732422\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-72\" x=\"316.255859\"/>\n",
       "    </g>\n",
       "    <!-- trouser -->\n",
       "    <g transform=\"translate(455.587009 29.7555)scale(0.12 -0.12)\">\n",
       "     <use xlink:href=\"#DejaVuSans-74\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-72\" x=\"39.208984\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6f\" x=\"78.072266\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-75\" x=\"139.253906\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-73\" x=\"202.632812\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-65\" x=\"254.732422\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-72\" x=\"316.255859\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p2c45364fe9\">\n",
       "   <rect x=\"10.7\" y=\"35.7555\" width=\"71.742857\" height=\"71.742857\"/>\n",
       "  </clipPath>\n",
       "  <clipPath id=\"p22d63f10d7\">\n",
       "   <rect x=\"96.791429\" y=\"35.7555\" width=\"71.742857\" height=\"71.742857\"/>\n",
       "  </clipPath>\n",
       "  <clipPath id=\"pb13de5ccd3\">\n",
       "   <rect x=\"182.882857\" y=\"35.7555\" width=\"71.742857\" height=\"71.742857\"/>\n",
       "  </clipPath>\n",
       "  <clipPath id=\"p50336d2915\">\n",
       "   <rect x=\"268.974286\" y=\"35.7555\" width=\"71.742857\" height=\"71.742857\"/>\n",
       "  </clipPath>\n",
       "  <clipPath id=\"p98f307e631\">\n",
       "   <rect x=\"355.065714\" y=\"35.7555\" width=\"71.742857\" height=\"71.742857\"/>\n",
       "  </clipPath>\n",
       "  <clipPath id=\"p0fffecee77\">\n",
       "   <rect x=\"441.157143\" y=\"35.7555\" width=\"71.742857\" height=\"71.742857\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 900x150 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def predict_ch3(net, test_iter, n=6):  #@save\n",
    "    \"\"\"预测标签（定义见第3章）\"\"\"\n",
    "    for X, y in test_iter:\n",
    "        break\n",
    "    trues = d2l.get_fashion_mnist_labels(y)\n",
    "    preds = d2l.get_fashion_mnist_labels(net(X).argmax(axis=1))\n",
    "    titles = [true +'\\n' + pred for true, pred in zip(trues, preds)]\n",
    "    d2l.show_images(\n",
    "        X[0:n].reshape((n, 28, 28)), 1, n, titles=titles[0:n])\n",
    "\n",
    "predict_ch3(net, test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49465c0e-8d93-48a4-ac35-d5bb5bc96d6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
